{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "import scipy.stats as stats\n",
    "import pyentrp.entropy as ent\n",
    "import pywt\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_eeg_data(participant_id, file_path_template=\"eegs/{participant_id}.bdf\"):\n",
    "    \"\"\"\n",
    "    Load EEG data for a given participant.\n",
    "    \n",
    "    Args:\n",
    "    - participant_id (str): Participant ID.\n",
    "    - file_path_template (str): Template for file path.\n",
    "    \n",
    "    Returns:\n",
    "    - raw_eeg (mne.io.Raw): The raw EEG data.\n",
    "    \"\"\"\n",
    "    file_path = file_path_template.format(participant_id=participant_id)\n",
    "    raw = mne.io.read_raw_bdf(file_path, preload=True)\n",
    "    \n",
    "    # Keep only EEG channels\n",
    "    raw_eeg = raw.pick_types(eeg=True)\n",
    "    return raw_eeg\n",
    "\n",
    "\n",
    "def reorder_eeg_channels(raw_eeg, channel_names_geneva):\n",
    "    \"\"\"\n",
    "    Reorder EEG channels to Geneva order.\n",
    "    \n",
    "    Args:\n",
    "    - raw_eeg (mne.io.Raw): The raw EEG data.\n",
    "    - channel_names_geneva (list): List of channel names in Geneva order.\n",
    "    \n",
    "    Returns:\n",
    "    - raw_reordered (mne.io.Raw): Reordered EEG data.\n",
    "    \"\"\"\n",
    "    raw_reordered = raw_eeg.reorder_channels(channel_names_geneva)\n",
    "    return raw_reordered\n",
    "\n",
    "\n",
    "def process_participants(participant_ids, channel_names_geneva):\n",
    "    \"\"\"\n",
    "    Process EEG data for all participants, load and reorder channels.\n",
    "    \n",
    "    Args:\n",
    "    - participant_ids (list): List of participant IDs.\n",
    "    - channel_names_geneva (list): List of channel names in Geneva order.\n",
    "    \n",
    "    Returns:\n",
    "    - eeg_data_reordered (dict): Dictionary with participant ID as keys and reordered EEG data as values.\n",
    "    \"\"\"\n",
    "    eeg_data_reordered = {}\n",
    "    \n",
    "    for participant_id in participant_ids:\n",
    "        raw_eeg = load_eeg_data(participant_id)\n",
    "        raw_reordered = reorder_eeg_channels(raw_eeg, channel_names_geneva)\n",
    "        \n",
    "        # Store reordered EEG data\n",
    "        eeg_data_reordered[participant_id] = raw_reordered\n",
    "    \n",
    "    return eeg_data_reordered\n",
    "\n",
    "\n",
    "def print_eeg_channel_info(participant_id, raw, raw_reordered):\n",
    "    \"\"\"\n",
    "    Prints channel information before and after reordering for a participant.\n",
    "    \n",
    "    Args:\n",
    "    - participant_id (str): The ID of the participant.\n",
    "    - raw (mne.io.Raw): The original raw EEG data.\n",
    "    - raw_reordered (mne.io.Raw): The reordered EEG data.\n",
    "    \"\"\"\n",
    "    print(f\"Participant ID: {participant_id}\")\n",
    "    \n",
    "    # Print channel names before and after reordering\n",
    "    print(\"Channel names before reordering:\", raw.info['ch_names'])\n",
    "    print(\"Channel names after reordering:\", raw_reordered.info['ch_names'])\n",
    "    \n",
    "    # Print EEG data shape before and after reordering\n",
    "    print(\"EEG data shape before reordering:\", raw._data.shape)\n",
    "    print(\"EEG data shape after reordering:\", raw_reordered._data.shape)\n",
    "\n",
    "def plot_sensor_locations(raw, raw_reordered, show_plots=True):\n",
    "    \"\"\"\n",
    "    Plots sensor locations before and after reordering.\n",
    "    \n",
    "    Args:\n",
    "    - raw (mne.io.Raw): The original raw EEG data.\n",
    "    - raw_reordered (mne.io.Raw): The reordered EEG data.\n",
    "    - show_plots (bool): Whether to display the plots.\n",
    "    \"\"\"\n",
    "    if show_plots:\n",
    "        # Plot channel locations before reordering\n",
    "        fig_before = raw.plot_sensors(show_names=True, title=\"Channel Locations Before Reordering\")\n",
    "        plt.show()\n",
    "        \n",
    "        # Plot channel locations after reordering\n",
    "        fig_after = raw_reordered.plot_sensors(show_names=True, title=\"Channel Locations After Reordering\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def process_participant_info(eeg_data_reordered, raw_data, show_plots=False):\n",
    "    \"\"\"\n",
    "    Process and display information for each participant, including channel names, \n",
    "    data shapes, and sensor plots.\n",
    "    \n",
    "    Args:\n",
    "    - eeg_data_reordered (dict): Dictionary with participant IDs as keys and reordered EEG data as values.\n",
    "    - raw_data (dict): Dictionary with participant IDs as keys and original raw EEG data as values.\n",
    "    - show_plots (bool): Whether to display sensor plots.\n",
    "    \"\"\"\n",
    "    for participant_id, raw_reordered in eeg_data_reordered.items():\n",
    "        raw = raw_data[participant_id]\n",
    "        \n",
    "        # Print EEG channel and data shape information\n",
    "        print_eeg_channel_info(participant_id, raw, raw_reordered)\n",
    "        \n",
    "        # Optionally plot sensor locations\n",
    "        if show_plots:\n",
    "            plot_sensor_locations(raw, raw_reordered, show_plots)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define parameters\n",
    "channel_names_geneva = ['Fp1', 'AF3', 'F3', 'F7', 'FC5', 'FC1', 'C3', 'T7', 'CP5', 'CP1', 'P3', 'P7', 'PO3', 'O1', 'Oz', 'Pz', 'Fp2', 'AF4', 'Fz', 'F4', 'F8', 'FC6', 'FC2', 'Cz', 'C4', 'T8', 'CP6', 'CP2', 'P4', 'P8', 'PO4', 'O2']\n",
    "participant_ids = [f\"s{i:02d}\" for i in range(1, 3)]  # Assuming 5 participants\n",
    "\n",
    "# Load the raw EEG data for each participant\n",
    "raw_data = {participant_id: load_eeg_data(participant_id) for participant_id in participant_ids}\n",
    "\n",
    "# Process (reorder) the participants' data\n",
    "eeg_data_reordered = process_participants(participant_ids, channel_names_geneva)\n",
    "\n",
    "# Print information about the loaded and reordered data\n",
    "process_participant_info(eeg_data_reordered, raw_data, show_plots=False)  # Toggle `show_plots` to True if you want to see plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_participant_ratings(file_path):\n",
    "    \"\"\"\n",
    "    Load participant ratings from a CSV file.\n",
    "    \n",
    "    Args:\n",
    "    - file_path (str): Path to the CSV file containing participant ratings.\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame: A pandas DataFrame containing the participant ratings.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    return df\n",
    "\n",
    "def sort_ratings(df):\n",
    "    \"\"\"\n",
    "    Sort the DataFrame by Participant ID and Experiment ID.\n",
    "    \n",
    "    Args:\n",
    "    - df (DataFrame): The DataFrame containing participant ratings.\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame: The sorted DataFrame.\n",
    "    \"\"\"\n",
    "    df_sorted = df.sort_values(by=['Participant_id', 'Experiment_id'])\n",
    "    return df_sorted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_trial_data(participant_id_str, participant_data, raw_data):\n",
    "    \"\"\"\n",
    "    Extracts trial data for a specific participant.\n",
    "    \n",
    "    Args:\n",
    "    - participant_id_str (str): The ID of the participant.\n",
    "    - participant_data (DataFrame): The DataFrame containing trial information for the participant.\n",
    "    - raw_data (mne.io.Raw): The raw EEG data for the participant.\n",
    "    \n",
    "    Returns:\n",
    "    - List: A list containing trial data for the participant.\n",
    "    \"\"\"\n",
    "    trials = []\n",
    "    \n",
    "    # Iterate over each trial for the current participant\n",
    "    for index, trial in participant_data.iterrows():\n",
    "        # Extract the start time of the trial (in seconds)\n",
    "        start_time = trial['Start_time'] / 1e6  # Convert microseconds to seconds\n",
    "        \n",
    "        # Define the start and end time of the trial (assuming 1-minute duration)\n",
    "        end_time = start_time + 60  # 1-minute duration\n",
    "        \n",
    "        # Extract the trial data based on the start and end time\n",
    "        trial_data = raw_data.copy().crop(tmin=start_time, tmax=end_time)\n",
    "        \n",
    "        # Store the trial data in the list for the current participant\n",
    "        trials.append(trial_data)\n",
    "        \n",
    "        # Print participant ID and trial information (optional)\n",
    "        # print(participant_id_str, trial)\n",
    "    \n",
    "    return trials\n",
    "\n",
    "def process_participant_trials(participant_ids, trial_info, eeg_data_reordered):\n",
    "    \"\"\"\n",
    "    Processes trial data for all participants.\n",
    "    \n",
    "    Args:\n",
    "    - participant_ids (list): List of participant IDs.\n",
    "    - trial_info (DataFrame): The sorted DataFrame containing trial information.\n",
    "    - eeg_data_reordered (dict): Dictionary with participant IDs as keys and reordered EEG data as values.\n",
    "    \n",
    "    Returns:\n",
    "    - dict: A dictionary containing trial data for each participant.\n",
    "    \"\"\"\n",
    "    participant_trials = {participant_id: [] for participant_id in participant_ids}\n",
    "\n",
    "    # Iterate over each participant's data\n",
    "    for participant_id, participant_data in trial_info.groupby('Participant_id'):\n",
    "        participant_id_str = f\"s{participant_id:02d}\"  # Convert participant_id to string format\n",
    "        if participant_id_str not in participant_ids:\n",
    "            continue\n",
    "        \n",
    "        # Get the raw EEG data for the current participant\n",
    "        raw_data = eeg_data_reordered[participant_id_str]\n",
    "\n",
    "        # Extract trial data for the current participant\n",
    "        trials = extract_trial_data(participant_id_str, participant_data, raw_data)\n",
    "        \n",
    "        # Store trial data in the dictionary\n",
    "        participant_trials[participant_id_str] = trials\n",
    "    \n",
    "    return participant_trials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load and sort participant ratings\n",
    "ratings_file_path = \"participant_ratings.csv\"\n",
    "df = load_participant_ratings(ratings_file_path)  # Load ratings data\n",
    "df_sorted = sort_ratings(df)  # Sort the data\n",
    "\n",
    "# Process trial data for all participants\n",
    "participant_trials = process_participant_trials(participant_ids, df_sorted, eeg_data_reordered)\n",
    "\n",
    "# Example: Print the number of trials for each participant\n",
    "for participant_id, trials in participant_trials.items():\n",
    "    print(f\"Participant ID: {participant_id}, Number of Trials: {len(trials)}\")\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot PSD for the first trial data of the first participant\n",
    "first_participant_trials = participant_trials['s01']\n",
    "first_trial_data = first_participant_trials[0]\n",
    "\n",
    "\n",
    "# Plot the first trial data\n",
    "first_trial_data.plot()\n",
    "# Plot the power spectral density (PSD)\n",
    "first_trial_data.compute_psd().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREPROCESSING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_common_average_reference(trials):\n",
    "    \"\"\"\n",
    "    Apply Common Average Reference (CAR) to the given trials.\n",
    "\n",
    "    Args:\n",
    "    - trials (list): A list of mne.io.Raw objects representing the trials.\n",
    "\n",
    "    Returns:\n",
    "    - list: A list of mne.io.Raw objects with CAR applied.\n",
    "    \"\"\"\n",
    "    trials_with_car = []\n",
    "    \n",
    "    for trial_data in trials:\n",
    "        # Create a copy of the trial data\n",
    "        trial_with_car = trial_data.copy()\n",
    "        # Set the EEG reference to average and apply projection\n",
    "        trial_with_car.set_eeg_reference('average', projection=False)\n",
    "        trial_with_car.apply_proj()  # Apply the projection\n",
    "        trials_with_car.append(trial_with_car)\n",
    "        \n",
    "        print(trial_data.info['projs'])\n",
    "\n",
    "    for trial_data in trials_with_car:\n",
    "        print(\"Mean of each channel after CAR:\", trial_data.get_data().mean(axis=1))\n",
    "\n",
    "\n",
    "    \n",
    "    return trials_with_car\n",
    "\n",
    "def apply_bandpass_filter(trials, low_freq, high_freq):\n",
    "    \"\"\"\n",
    "    Apply band-pass filter to the given trials.\n",
    "\n",
    "    Args:\n",
    "    - trials (list): A list of mne.io.Raw objects representing the trials.\n",
    "    - low_freq (float): Lower cutoff frequency in Hz.\n",
    "    - high_freq (float): Upper cutoff frequency in Hz.\n",
    "\n",
    "    Returns:\n",
    "    - list: A list of mne.io.Raw objects with the band-pass filter applied.\n",
    "    \"\"\"\n",
    "    filtered_trials = []\n",
    "    \n",
    "    for trial_data in trials:\n",
    "        # Create a copy of the trial data\n",
    "        filtered_trial = trial_data.copy()\n",
    "        # Apply band-pass filter\n",
    "        filtered_trial.filter(low_freq, high_freq)\n",
    "        filtered_trials.append(filtered_trial)\n",
    "    \n",
    "    return filtered_trials\n",
    "\n",
    "\n",
    "def apply_notch_filter(trials, notch_freqs):\n",
    "    \"\"\"\n",
    "    Apply notch filters to the given trials.\n",
    "\n",
    "    Args:\n",
    "    - trials (list): A list of mne.io.Raw objects representing the trials.\n",
    "    - notch_freqs (list): A list of frequencies to apply notch filters.\n",
    "\n",
    "    Returns:\n",
    "    - list: A list of mne.io.Raw objects with the notch filters applied.\n",
    "    \"\"\"\n",
    "    notch_filtered_trials = []\n",
    "    \n",
    "    for trial_data in trials:\n",
    "        # Create a copy of the trial data\n",
    "        notch_filtered_trial = trial_data.copy()\n",
    "        # Apply notch filter for each frequency in the list\n",
    "        for freq in notch_freqs:\n",
    "            notch_filtered_trial.notch_filter(freqs=freq, verbose=True)\n",
    "        notch_filtered_trials.append(notch_filtered_trial)\n",
    "    \n",
    "    return notch_filtered_trials\n",
    "\n",
    "\n",
    "def apply_resampling(trials, new_sampling_rate):\n",
    "    \"\"\"\n",
    "    Resample the given trials to the new sampling rate.\n",
    "\n",
    "    Args:\n",
    "    - trials (list): A list of mne.io.Raw objects representing the trials.\n",
    "    - new_sampling_rate (int): The desired sampling rate.\n",
    "\n",
    "    Returns:\n",
    "    - list: A list of mne.io.Raw objects resampled to the new sampling rate.\n",
    "    \"\"\"\n",
    "    resampled_trials = []\n",
    "    \n",
    "    for trial_data in trials:\n",
    "        # Resample trial data\n",
    "        resampled_trial = trial_data.copy().resample(new_sampling_rate, npad=\"auto\")\n",
    "        resampled_trials.append(resampled_trial)\n",
    "    \n",
    "    return resampled_trials\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Common Average Reference (CAR)\n",
    "car_participant_data = {}\n",
    "for participant_id, trials in participant_trials.items():\n",
    "    car_participant_data[participant_id] = apply_common_average_reference(trials)\n",
    "\n",
    "first_participant_id = 's01'\n",
    "first_car_trial = car_participant_data[first_participant_id][0]\n",
    "\n",
    "# Plot the trial data after resampling\n",
    "first_car_trial.plot(title=\"EEG Data for Participant s01 - Trial 1 (Common Average Reference)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply band-pass filter\n",
    "low_freq = 4  # Lower cutoff frequency in Hz\n",
    "high_freq = 45  # Upper cutoff frequency in Hz\n",
    "filtered_participant_data = {}\n",
    "for participant_id, trials in car_participant_data.items():\n",
    "    filtered_participant_data[participant_id] = apply_bandpass_filter(trials, low_freq, high_freq)\n",
    "\n",
    "first_filtered_trial = filtered_participant_data[first_participant_id][0]\n",
    "\n",
    "# Plot the trial data after resampling\n",
    "first_filtered_trial.plot(title=\"EEG Data for Participant s01 - Trial 1 (After band-pass filtering)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply notch filter\n",
    "notch_freqs = [50, 60]  # Notch filter frequencies in Hz\n",
    "notch_filtered_participant_data = {}\n",
    "for participant_id, trials in filtered_participant_data.items():\n",
    "    notch_filtered_participant_data[participant_id] = apply_notch_filter(trials, notch_freqs)\n",
    "\n",
    "first_notch_filtered_trial = notch_filtered_participant_data[first_participant_id][0]\n",
    "\n",
    "# Plot the trial data after resampling\n",
    "first_notch_filtered_trial.plot(title=\"EEG Data for Participant s01 - Trial 1 (After notch filtering)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample the data\n",
    "new_sampling_rate = 128  # Desired sampling rate\n",
    "resampled_participant_data = {}\n",
    "for participant_id, trials in notch_filtered_participant_data.items():\n",
    "    resampled_participant_data[participant_id] = apply_resampling(trials, new_sampling_rate)\n",
    "\n",
    "\n",
    "first_resampled_trial = resampled_participant_data[first_participant_id][0]\n",
    "\n",
    "# Plot the trial data after resampling\n",
    "first_resampled_trial.plot(title=\"EEG Data for Participant s01 - Trial 1 (After Resampling)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne.preprocessing import ICA\n",
    "from mne_icalabel import label_components\n",
    "\n",
    "def perform_ica(trials, montage, variance_proportion=0.999):\n",
    "    \"\"\"\n",
    "    Apply Independent Component Analysis (ICA) to clean EEG trials.\n",
    "\n",
    "    Args:\n",
    "    - trials (list): A list of mne.io.Raw objects representing the trials.\n",
    "    - montage (mne.channels.DigMontage): The montage to set for the EEG data.\n",
    "    - variance_proportion (float): Proportion of variance to explain (0.999 by default).\n",
    "\n",
    "    Returns:\n",
    "    - cleaned_trials (list): A list of cleaned mne.io.Raw objects.\n",
    "    - ica_models (list): A list of ICA models fitted to each trial.\n",
    "    \"\"\"\n",
    "    cleaned_trials = []\n",
    "    ica_models = []\n",
    "\n",
    "    for i, trial_data in enumerate(trials):\n",
    "        # Set the montage\n",
    "        trial_data.set_montage(montage)\n",
    "\n",
    "        # Fit ICA with a proportion of variance\n",
    "        ica = ICA(n_components=variance_proportion, method='infomax', fit_params=dict(extended=True), random_state=97, max_iter=1000)\n",
    "        ica.fit(trial_data)\n",
    "        \n",
    "\n",
    "        # Store the fitted ICA model\n",
    "        ica_models.append(ica)\n",
    "\n",
    "        # Optionally: Label components using mne_icalabel\n",
    "        labels = label_components(trial_data, ica, method='iclabel')\n",
    "\n",
    "        # # Print labels for inspection\n",
    "        # print(f'Trial {i + 1} component labels:')\n",
    "        # print(labels)\n",
    "\n",
    "        # Identify indices of components to exclude (not 'brain' or 'other')\n",
    "        components_to_exclude = [j for j, label in enumerate(labels['labels']) if label not in ['brain']]\n",
    "        ica.exclude = components_to_exclude\n",
    "\n",
    "        # Apply ICA to the data, removing the unwanted components\n",
    "        cleaned_data = ica.apply(trial_data, exclude=ica.exclude)\n",
    "\n",
    "        # Store cleaned trial data\n",
    "        cleaned_trials.append(cleaned_data)\n",
    "\n",
    "        # # Optionally: Show new labels after cleaning\n",
    "        # new_labels = label_components(cleaned_data, ica, method='iclabel')\n",
    "        # print(f'Trial {i + 1} cleaned component labels:')\n",
    "        # print(new_labels)\n",
    "\n",
    "    return cleaned_trials, ica_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the montage for the EEG data\n",
    "montage = mne.channels.make_standard_montage('standard_1020')\n",
    "\n",
    "# Apply ICA to clean the EEG data for each participant\n",
    "cleaned_participant_data = {}\n",
    "for participant_id, trials in resampled_participant_data.items():\n",
    "    cleaned_trials, ica_models = perform_ica(trials, montage)\n",
    "    cleaned_participant_data[participant_id] = cleaned_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Plot the EEG data for the first trial of the first participant after resampling\n",
    "first_participant_id = 's01'\n",
    "first_cleaned_trial = cleaned_participant_data[first_participant_id][0]\n",
    "\n",
    "# Plot the trial data after resampling\n",
    "first_cleaned_trial.plot(title=\"EEG Data for Participant s01 - Trial 1 (After ICA)\")\n",
    "first_cleaned_trial.compute_psd().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_trials(data, epoch_duration=1.0, discard_duration=3.0):\n",
    "    \"\"\"\n",
    "    Epoch the EEG data for each trial in the provided dictionary of resampled data.\n",
    "\n",
    "    Args:\n",
    "    - resampled_data (dict): A dictionary with participant IDs as keys and lists of mne.io.Raw objects as values.\n",
    "    - epoch_duration (float): Duration of each epoch in seconds (default: 1.0).\n",
    "    - discard_duration (float): Duration to discard from the start of each trial in seconds (default: 3.0).\n",
    "\n",
    "    Returns:\n",
    "    - dict: A dictionary with participant IDs as keys and lists of epoched trials as values.\n",
    "    \"\"\"\n",
    "    epoched_data = {}\n",
    "\n",
    "    # Loop through each participant's trials\n",
    "    for participant_id, trials in data.items():\n",
    "        epoched_trials = []\n",
    "        \n",
    "        # Process each trial for the current participant\n",
    "        for trial_data in trials:\n",
    "            # Generate events for fixed-length epochs after discarding initial seconds\n",
    "            events = mne.make_fixed_length_events(trial_data, start=discard_duration, duration=epoch_duration)\n",
    "\n",
    "            # Check if events were successfully created\n",
    "            if len(events) == 0:\n",
    "                print(f\"No events created for participant {participant_id}'s trial. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Create epochs from the events\n",
    "            epochs = mne.Epochs(trial_data, events, tmin=0.0, tmax=epoch_duration, baseline=None, preload=True, detrend=1)\n",
    "\n",
    "            # Append epochs if they contain data\n",
    "            if epochs.get_data().size > 0:\n",
    "                epoched_trials.append(epochs)\n",
    "            else:\n",
    "                print(f\"No data after epoching for participant {participant_id}'s trial. Skipping.\")\n",
    "\n",
    "        epoched_data[participant_id] = epoched_trials\n",
    "\n",
    "    return epoched_data\n",
    "\n",
    "\n",
    "\n",
    "def create_epoch_dataframe(df, num_participants=2, epochs_per_trial=56):\n",
    "    \"\"\"\n",
    "    Create a DataFrame containing epoch information for each trial.\n",
    "    \n",
    "    Args:\n",
    "    - df_sorted (pd.DataFrame): Sorted DataFrame containing columns 'Participant_id', 'Experiment_id', 'Valence', 'Arousal'.\n",
    "    - num_participants (int): Number of participants to include in the output (default: 5).\n",
    "    - epochs_per_trial (int): Number of epochs per trial (default: 57).\n",
    "    \n",
    "    Returns:\n",
    "    - epoch_df (pd.DataFrame): A DataFrame containing 'Participant_ID', 'Experiment_ID', 'Epoch_ID', 'Valence', 'Arousal'.\n",
    "    \"\"\"\n",
    "    epoch_data = []  # List to store epoch data\n",
    "\n",
    "    # Get unique participant IDs and limit to the specified number\n",
    "    unique_participants = df['Participant_id'].unique()[:num_participants]\n",
    "\n",
    "    # Iterate through each row in the sorted DataFrame\n",
    "    for _, row in df.iterrows():\n",
    "        participant_id = row['Participant_id']\n",
    "\n",
    "        # Check if the participant is in the limited list\n",
    "        if participant_id not in unique_participants:\n",
    "            continue  # Skip if the participant is not in the selected range\n",
    "\n",
    "        experiment_id = row['Experiment_id']\n",
    "        valence = row['Valence']\n",
    "        arousal = row['Arousal']\n",
    "\n",
    "        # For each trial, replicate the valence and arousal for all epochs\n",
    "        for epoch in range(1, epochs_per_trial + 1):\n",
    "            epoch_data.append({\n",
    "                'Participant_ID': participant_id,\n",
    "                'Experiment_ID': experiment_id,\n",
    "                'Epoch_ID': epoch,\n",
    "                'Valence': valence,\n",
    "                'Arousal': arousal\n",
    "            })\n",
    "\n",
    "    # Create a new DataFrame from the epoch data\n",
    "    epoch_df = pd.DataFrame(epoch_data)\n",
    "    \n",
    "    return epoch_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epoch the data for each participant's trials\n",
    "epoched_participant_data = epoch_trials(cleaned_participant_data, epoch_duration=1.0, discard_duration=3.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of epochs for each participant and the events in each epoch\n",
    "for participant_id, trials in epoched_participant_data.items():\n",
    "    print(f\"Participant {participant_id} has {len(trials)} trials.\")\n",
    "    \n",
    "    for trials_index, trials in enumerate(trials):\n",
    "        \n",
    "        print(f\"  trial {trials_index + 1} has {len(trials.events)} epochs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_epoch = epoched_participant_data[first_participant_id][0][0]\n",
    "\n",
    "# Plot the trial data after resampling\n",
    "example_epoch.plot(title=\"EEG Data for Participant s01 - Trial 1 (After Preprocessing and Resampling)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "epoch_df = create_epoch_dataframe(df_sorted, num_participants=2, epochs_per_trial=56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "END OF PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class EEGFeatureExtractor(nn.Module):\n",
    "    def __init__(self, input_channels=32, input_time_samples=128, output_dim=64):\n",
    "        super(EEGFeatureExtractor, self).__init__()\n",
    "\n",
    "        # First Conv Block\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3, 3), padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.pool1 = nn.MaxPool2d((2, 2))\n",
    "        self.drop1 = nn.Dropout(0.3)\n",
    "        \n",
    "        # Second Conv Block\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.pool2 = nn.MaxPool2d((2, 2))\n",
    "        self.drop2 = nn.Dropout(0.3)\n",
    "        \n",
    "        # Third Conv Block\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3, 3), padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.pool3 = nn.MaxPool2d((2, 2))\n",
    "        self.drop3 = nn.Dropout(0.4)\n",
    "\n",
    "        # Calculate flattened dimensions after convolutions and pooling\n",
    "        # After 3 MaxPool2d layers, height and width are reduced by a factor of 8\n",
    "        self.flatten_dim = 128 * (input_channels // 8) * (input_time_samples // 8)\n",
    "        \n",
    "        # GRU Layer for Temporal Features\n",
    "        self.gru = nn.GRU(input_size=self.flatten_dim, hidden_size=256, batch_first=True)\n",
    "        \n",
    "        # Fully Connected Layers for Feature Compression\n",
    "        self.fc1 = nn.Linear(256, 128)\n",
    "        self.drop_fc1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Forward pass through conv layers\n",
    "        x = self.drop1(self.pool1(torch.relu(self.bn1(self.conv1(x)))))\n",
    "        x = self.drop2(self.pool2(torch.relu(self.bn2(self.conv2(x)))))\n",
    "        x = self.drop3(self.pool3(torch.relu(self.bn3(self.conv3(x)))))\n",
    "        \n",
    "        # Reshape for GRU: (batch_size, sequence_length, features)\n",
    "        x = x.view(x.size(0), -1, self.flatten_dim)  # Ensure this shape is correct\n",
    "        _, h_n = self.gru(x)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = torch.relu(self.fc1(h_n[-1]))  # Take the last hidden state of GRU\n",
    "        x = self.drop_fc1(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Initialize model, optimizer, and loss\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = EEGFeatureExtractor(input_channels=32, input_time_samples=128, output_dim=64).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.MSELoss()  # Modify if you have labels\n",
    "\n",
    "# Example input tensor (batch_size, channels, height, width)\n",
    "# For instance, a batch of 16 samples, each with 1 channel, 32 height, and 128 width\n",
    "input_tensor = torch.randn(16, 1, 32, 128).to(device)\n",
    "output = model(input_tensor)  # Forward pass\n",
    "print(output.shape)  # Should print the shape of the output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, epoched_data, epoch_df):\n",
    "        self.epoched_data = epoched_data\n",
    "        self.epoch_df = epoch_df  # Use epoch_df for labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.epoch_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the participant, trial, and epoch IDs from the current epoch row\n",
    "        row = self.epoch_df.iloc[idx]\n",
    "\n",
    "        # Format the participant_id correctly\n",
    "        participant_id = f\"s{int(row['Participant_ID']):02d}\"\n",
    "        trial_id = int(row['Experiment_ID'])\n",
    "        epoch_id = int(row['Epoch_ID'])\n",
    "\n",
    "        # Check if the participant_id exists in the epoched data\n",
    "        if participant_id not in self.epoched_data:\n",
    "            raise KeyError(f\"Participant ID '{participant_id}' not found in epoched_data.\")\n",
    "\n",
    "        # Retrieve the EEG data from epoched_data\n",
    "        try:\n",
    "            eeg_data = self.epoched_data[participant_id][trial_id - 1][epoch_id - 1]\n",
    "        except IndexError as e:\n",
    "            raise IndexError(f\"Error accessing data for Participant '{participant_id}', Trial '{trial_id}', Epoch '{epoch_id}': {str(e)}\")\n",
    "\n",
    "        # Debugging: Print the type of the retrieved EEG data\n",
    "        print(f\"Type of eeg_data for {participant_id}, Trial {trial_id}, Epoch {epoch_id}: {type(eeg_data)}\")\n",
    "\n",
    "        # If eeg_data is an instance of a class (like Epochs), you need to extract the underlying data\n",
    "        if hasattr(eeg_data, 'get_data'):\n",
    "            eeg_data = eeg_data.get_data()\n",
    "        elif hasattr(eeg_data, 'data'):\n",
    "            eeg_data = eeg_data.data\n",
    "\n",
    "        # Check if we successfully retrieved a NumPy array or something similar\n",
    "        if not isinstance(eeg_data, (np.ndarray, list)):\n",
    "            raise ValueError(f\"Unexpected data format for eeg_data: {eeg_data}\")\n",
    "\n",
    "        # Print the shape of the retrieved EEG data\n",
    "        print(f\"Shape of eeg_data for {participant_id}, Trial {trial_id}, Epoch {epoch_id}: {np.array(eeg_data).shape}\")\n",
    "\n",
    "        # Convert eeg_data to tensor\n",
    "        eeg_data = torch.tensor(eeg_data, dtype=torch.float32)\n",
    "\n",
    "        # Ensure the shape is correct (add channel dimension if necessary)\n",
    "        eeg_data = eeg_data.unsqueeze(0)  # Add a channel dimension if required by your model\n",
    "\n",
    "        # Retrieve valence and arousal\n",
    "        valence = float(row['Valence'])\n",
    "        arousal = float(row['Arousal'])\n",
    "\n",
    "        return eeg_data, (valence, arousal)\n",
    "\n",
    "# Dataset and DataLoader setup\n",
    "dataset = EEGDataset(epoched_participant_data, epoch_df)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=4)  # Adjust num_workers as needed\n",
    "\n",
    "# # Run feature extraction\n",
    "# df_extracted_features = extract_features(model, dataloader)\n",
    "# df_extracted_features.to_csv('eeg_extracted_features.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation function to extract features\n",
    "def extract_features(model, dataloader):\n",
    "    model.eval()\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch, labels in dataloader:\n",
    "            batch = batch.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass through the model\n",
    "            features = model(batch)\n",
    "            \n",
    "            # Flatten features and move to CPU\n",
    "            features = features.view(features.size(0), -1).cpu().numpy()\n",
    "            all_features.append(features)\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    all_features = np.vstack(all_features)\n",
    "    all_labels = np.vstack(all_labels)\n",
    "    df_features = pd.DataFrame(all_features, columns=[f'feature_{i}' for i in range(all_features.shape[1])])\n",
    "    df_labels = pd.DataFrame(all_labels, columns=['Valence', 'Arousal'])\n",
    "    df_combined = pd.concat([df_features, df_labels], axis=1)\n",
    "    \n",
    "    return df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run feature extraction\n",
    "df_extracted_features = extract_features(model, dataloader)\n",
    "df_extracted_features.to_csv('eeg_extracted_features.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
