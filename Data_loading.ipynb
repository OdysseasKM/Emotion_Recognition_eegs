{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of participant IDs\n",
    "participant_ids = [f\"s{i:02d}\" for i in range(1, 6)]  # Assuming 5 participants\n",
    "\n",
    "# Dictionary to store EEG data for each participant\n",
    "eeg_data = {}\n",
    "\n",
    "# Load EEG data for each participant\n",
    "for participant_id in participant_ids:\n",
    "    file_path = f\"eegs/{participant_id}.bdf\"\n",
    "    raw = mne.io.read_raw_bdf(file_path, preload=True)\n",
    "    eeg_data[participant_id] = raw\n",
    "\n",
    "# Print information about loaded data\n",
    "for participant_id, raw in eeg_data.items():\n",
    "    print(f\"Participant ID: {participant_id}\")\n",
    "    # print(raw.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "\n",
    "# Define the channel names and indices for Twente and Geneva\n",
    "channel_names_geneva = ['Fp1', 'AF3', 'F3', 'F7', 'FC5', 'FC1', 'C3', 'T7', 'CP5', 'CP1', 'P3', 'P7', 'PO3', 'O1', 'Oz', 'Pz', 'Fp2', 'AF4', 'Fz', 'F4', 'F8', 'FC6', 'FC2', 'Cz', 'C4', 'T8', 'CP6', 'CP2', 'P4', 'P8', 'PO4', 'O2']\n",
    "\n",
    "# List of participant IDs\n",
    "participant_ids = [f\"s{i:02d}\" for i in range(1, 6)]  # Assuming 5 participants\n",
    "\n",
    "# Dictionary to store reordered EEG data for each participant\n",
    "eeg_data_reordered = {}\n",
    "\n",
    "# Load EEG data for each participant and reorder channels\n",
    "for participant_id in participant_ids:\n",
    "    file_path = f\"eegs/{participant_id}.bdf\"\n",
    "    raw = mne.io.read_raw_bdf(file_path, preload=True)\n",
    "    \n",
    "    # Keep only EEG channels\n",
    "    raw_eeg = raw.pick_types(eeg=True)\n",
    "    \n",
    "    # Reorder EEG channels to Geneva order\n",
    "    raw_reordered = raw_eeg.reorder_channels(channel_names_geneva)\n",
    "\n",
    "    # Store reordered EEG data\n",
    "    eeg_data_reordered[participant_id] = raw_reordered\n",
    "\n",
    "# Print information about loaded and reordered data\n",
    "for participant_id, raw_reordered in eeg_data_reordered.items():\n",
    "    print(f\"Participant ID: {participant_id}\")\n",
    "    print(\"Reordered EEG data shape:\", raw_reordered._data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Iterate through each participant\n",
    "for participant_id, raw_reordered in eeg_data_reordered.items():\n",
    "    print(f\"Participant ID: {participant_id}\")\n",
    "    \n",
    "    # Before reordering\n",
    "    print(\"Channel names before reordering:\", raw.info['ch_names'])\n",
    "    \n",
    "    # # Plot channel locations before reordering\n",
    "    # fig_before = raw.plot_sensors(show_names=True, title=\"Channel Locations Before Reordering\")\n",
    "    # plt.show()\n",
    "    \n",
    "    # After reordering\n",
    "    print(\"Channel names after reordering:\", raw_reordered.info['ch_names'])\n",
    "    \n",
    "    # # Plot channel locations after reordering\n",
    "    # fig_after = raw_reordered.plot_sensors(show_names=True, title=\"Channel Locations After Reordering\")\n",
    "    # plt.show()\n",
    "    \n",
    "    # Check data shape before and after reordering\n",
    "    print(\"EEG data shape before reordering:\", raw._data.shape)\n",
    "    print(\"EEG data shape after reordering:\", raw_reordered._data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(\"participant_ratings.csv\")\n",
    "\n",
    "# Sort the DataFrame based on 'Participant_id' and 'Experiment_id'\n",
    "df_sorted = df.sort_values(by=['Participant_id', 'Experiment_id'])\n",
    "\n",
    "# Display the sorted DataFrame\n",
    "print(df_sorted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store trial data for each participant\n",
    "participant_trials = {participant_id: [] for participant_id in participant_ids}\n",
    "\n",
    "# Load trial information from the CSV file\n",
    "# csv_file = 'participant_ratings.csv'  # Update with the actual file name\n",
    "# trial_info = pd.read_csv(csv_file)\n",
    "trial_info = df_sorted\n",
    "\n",
    "# Iterate over each participant's data for the first 5 participants\n",
    "for participant_id, participant_data in trial_info.groupby('Participant_id'):\n",
    "    participant_id_str = f\"s{participant_id:02d}\"  # Convert participant_id to string format\n",
    "    if participant_id_str not in participant_ids:\n",
    "        continue\n",
    "\n",
    "    # Get the raw EEG data for the current participant\n",
    "    raw_data = eeg_data_reordered[participant_id_str]\n",
    "\n",
    "    # Iterate over each trial for the current participant\n",
    "    for index, trial in participant_data.iterrows():\n",
    "        # Extract the start time of the trial (in seconds)\n",
    "        start_time = trial['Start_time'] / 1e6  # Convert microseconds to seconds\n",
    "\n",
    "        # Define the start and end time of the trial (assuming 1-minute duration)\n",
    "        end_time = start_time + 60  # 1-minute duration\n",
    "\n",
    "        # Extract the trial data based on the start and end time\n",
    "        trial_data = raw_data.copy().crop(tmin=start_time, tmax=end_time)\n",
    "\n",
    "        # Store the trial data in the list for the current participant\n",
    "        participant_trials[participant_id_str].append(trial_data)\n",
    "\n",
    "        # Print participant ID and trial information\n",
    "        print(participant_id_str, trial)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of participants\n",
    "num_participants = len(participant_trials)\n",
    "print(f\"Number of participants: {num_participants}\")\n",
    "\n",
    "# Get the number of trials for each participant\n",
    "for participant_id, trials in participant_trials.items():\n",
    "    num_trials = len(trials)\n",
    "    print(f\"Participant {participant_id}: Number of trials = {num_trials}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing the trial information DataFrame for the first participant\n",
    "first_participant_trial_info = trial_info[trial_info['Participant_id'] == 1]\n",
    "\n",
    "# Print the information of each trial\n",
    "for index, trial_data in first_participant_trial_info.iterrows():\n",
    "    print(f\"Trial {index + 1} info:\")\n",
    "    print(trial_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming '01' is the ID of the first participant\n",
    "first_participant_trials = participant_trials['s01']\n",
    "\n",
    "# Assuming the first trial is at index 0\n",
    "first_trial_data = first_participant_trials[0]\n",
    "\n",
    "# Plot the EEG data for the first trial\n",
    "first_trial_data.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the filter parameters\n",
    "low_freq = 4  # Lower cutoff frequency in Hz\n",
    "high_freq = 45  # Upper cutoff frequency in Hz\n",
    "\n",
    "# Iterate through each trial\n",
    "for i, trial_data in enumerate(first_participant_trials):\n",
    "    # Apply band-pass filter\n",
    "    filtered_trial_data = trial_data.filter(low_freq, high_freq)\n",
    "    \n",
    "    # Plot the EEG data for the first trial after filtering\n",
    "    if i == 0:\n",
    "        filtered_trial_data.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the notch filter frequencies\n",
    "notch_freqs = [50, 60]  # Notch filter frequencies in Hz\n",
    "\n",
    "# Iterate through each trial\n",
    "for i, trial_data in enumerate(first_participant_trials):\n",
    "    # Apply notch filters\n",
    "    for freq in notch_freqs:\n",
    "        trial_data.notch_filter(freqs=freq, verbose=True)\n",
    "    \n",
    "    # Plot the EEG data for the first trial after applying the notch filters\n",
    "    if i == 0:\n",
    "        trial_data.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the new sampling rate\n",
    "new_sampling_rate = 128\n",
    "\n",
    "# Resample each trial for the first participant\n",
    "for i, trial_data in enumerate(first_participant_trials):\n",
    "    first_participant_trials[i] = trial_data.resample(new_sampling_rate, npad=\"auto\")\n",
    "\n",
    "# Plot the EEG data for the first trial after resampling\n",
    "first_participant_trials[0].plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(first_trial_data.ch_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_trial_data.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_trial_data.plot_psd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(first_trial_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne.preprocessing import ICA\n",
    "\n",
    "# Set a fractional value for n_components\n",
    "n_components_fraction = 32\n",
    "\n",
    "# Initialize ICA with the extended Infomax method\n",
    "ica = ICA(n_components=n_components_fraction, method='infomax')\n",
    "\n",
    "# Fit the ICA model to your data\n",
    "ica.fit(first_trial_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot each component separately\n",
    "for i in range(len(ica.mixing_matrix_)):\n",
    "    plt.figure()\n",
    "    plt.plot(ica.mixing_matrix_[i])\n",
    "    plt.title(f\"Component {i+1}\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply CAR to each trial for the first participant\n",
    "for i, trial_data in enumerate(first_participant_trials):\n",
    "    first_participant_trials[i] = trial_data.copy().set_eeg_reference('average', projection=True)\n",
    "    first_participant_trials[i].apply_proj()\n",
    "\n",
    "# Plot the EEG data for the first trial after applying CAR\n",
    "first_participant_trials[0].plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the duration of each subtrial in seconds\n",
    "subtrial_duration = 1  # 1 second\n",
    "\n",
    "# Initialize a list to store the subtrials for all 40 trials of the first participant\n",
    "first_participant_subtrials = []\n",
    "\n",
    "# Iterate over each trial for the first participant\n",
    "for trial_data in first_participant_trials:\n",
    "    # Get the total duration of the trial in seconds\n",
    "    trial_duration = trial_data.times[-1]\n",
    "\n",
    "    # Calculate the number of subtrials\n",
    "    num_subtrials = int(np.floor(trial_duration / subtrial_duration))\n",
    "\n",
    "    # Initialize a list to store the subtrials for the current trial\n",
    "    trial_subtrials = []\n",
    "\n",
    "    # Iterate over each subtrial\n",
    "    for i in range(num_subtrials):\n",
    "        # Define the start and end time of the subtrial\n",
    "        start_time = i * subtrial_duration\n",
    "        end_time = (i + 1) * subtrial_duration\n",
    "\n",
    "        # Extract the subtrial data\n",
    "        subtrial_data = trial_data.copy().crop(tmin=start_time, tmax=end_time)\n",
    "\n",
    "        # Append the subtrial data to the list\n",
    "        trial_subtrials.append(subtrial_data)\n",
    "\n",
    "    # Append the list of subtrials for the current trial to the list for all trials\n",
    "    first_participant_subtrials.append(trial_subtrials)\n",
    "\n",
    "# Now you have a nested list where first_participant_subtrials[i][j] represents the j-th subtrial of the i-th trial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trial_subtrials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the first three subtrials from each trial's list of subtrials for all 40 trials of the first participant\n",
    "for trial_subtrials in first_participant_subtrials:\n",
    "    trial_subtrials = trial_subtrials[2:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trial_subtrials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Initialize lists to store computed Hjorth parameters for all trials of the first participant\n",
    "all_activities = []\n",
    "all_mobilities = []\n",
    "all_complexities = []\n",
    "\n",
    "# Iterate over each trial's list of subtrials\n",
    "for trial_subtrials in first_participant_subtrials:\n",
    "    # Initialize arrays to store computed Hjorth parameters for subtrials of the current trial\n",
    "    trial_activities = []\n",
    "    trial_mobilities = []\n",
    "    trial_complexities = []\n",
    "\n",
    "    # Compute Hjorth parameters for each subtrial of the current trial\n",
    "    for subtrial_data in trial_subtrials:\n",
    "        # Ensure the data is 2-dimensional\n",
    "        subtrial_data_2d = subtrial_data.get_data().squeeze()\n",
    "\n",
    "        # Compute the first derivative\n",
    "        dy = np.diff(subtrial_data_2d, axis=1)\n",
    "\n",
    "        # Compute the second derivative\n",
    "        dyy = np.diff(subtrial_data_2d, n=2, axis=1)\n",
    "\n",
    "        # Compute activity\n",
    "        activity = np.var(subtrial_data_2d, axis=1)\n",
    "\n",
    "        # Compute mobility\n",
    "        mobility = np.sqrt(np.var(dy, axis=1) / activity)\n",
    "\n",
    "        # Compute complexity\n",
    "        complexity = np.sqrt(np.var(dyy, axis=1) / np.var(dy, axis=1)) / mobility\n",
    "\n",
    "        # Append computed Hjorth parameters to respective arrays\n",
    "        trial_activities.append(activity)\n",
    "        trial_mobilities.append(mobility)\n",
    "        trial_complexities.append(complexity)\n",
    "\n",
    "    # Convert lists to arrays and append them to corresponding lists for all trials\n",
    "    all_activities.append(np.array(trial_activities))\n",
    "    all_mobilities.append(np.array(trial_mobilities))\n",
    "    all_complexities.append(np.array(trial_complexities))\n",
    "\n",
    "# Now all_activities, all_mobilities, and all_complexities contain the computed Hjorth parameters for each subtrial of all trials of the first participant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print computed Hjorth parameters for each subtrial of the first trial\n",
    "for i, (activity, mobility, complexity) in enumerate(zip(all_activities[0], all_mobilities[0], all_complexities[0]), start=1):\n",
    "    print(f\"Subtrial {i}:\")\n",
    "    print(f\"Activity: {activity}\")\n",
    "    print(f\"Mobility: {mobility}\")\n",
    "    print(f\"Complexity: {complexity}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Initialize lists to store mean Hjorth parameters for each trial\n",
    "trial_mean_activities = []\n",
    "trial_mean_mobilities = []\n",
    "trial_mean_complexities = []\n",
    "\n",
    "# Iterate over each trial\n",
    "for trial_activities, trial_mobilities, trial_complexities in zip(all_activities, all_mobilities, all_complexities):\n",
    "    # Compute the mean across all subtrials for each Hjorth parameter individually\n",
    "    mean_activity = np.mean(trial_activities, axis=0)\n",
    "    mean_mobility = np.mean(trial_mobilities, axis=0)\n",
    "    mean_complexity = np.mean(trial_complexities, axis=0)\n",
    "    \n",
    "    # Append the mean Hjorth parameters for the current trial to corresponding lists\n",
    "    trial_mean_activities.append(mean_activity)\n",
    "    trial_mean_mobilities.append(mean_mobility)\n",
    "    trial_mean_complexities.append(mean_complexity)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "trial_mean_activities = np.array(trial_mean_activities)\n",
    "trial_mean_mobilities = np.array(trial_mean_mobilities)\n",
    "trial_mean_complexities = np.array(trial_mean_complexities)\n",
    "\n",
    "# Print the shape of the resulting arrays\n",
    "print(\"Shape of trial_mean_activities:\", trial_mean_activities.shape)\n",
    "print(\"Shape of trial_mean_mobilities:\", trial_mean_mobilities.shape)\n",
    "print(\"Shape of trial_mean_complexities:\", trial_mean_complexities.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean of the 32 values for each trial\n",
    "trial_mean_activity_final = np.mean(trial_mean_activities, axis=1)\n",
    "trial_mean_mobility_final = np.mean(trial_mean_mobilities, axis=1)\n",
    "trial_mean_complexity_final = np.mean(trial_mean_complexities, axis=1)\n",
    "\n",
    "# Print the mean of the 32 values for each trial\n",
    "for i, (mean_activity, mean_mobility, mean_complexity) in enumerate(zip(trial_mean_activity_final, trial_mean_mobility_final, trial_mean_complexity_final), start=1):\n",
    "    print(f\"Trial {i}:\")\n",
    "    print(f\"Mean Activity: {mean_activity}\")\n",
    "    print(f\"Mean Mobility: {mean_mobility}\")\n",
    "    print(f\"Mean Complexity: {mean_complexity}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "outcome_df = pd.DataFrame()\n",
    "\n",
    "# Initialize lists to store participant ID, experiment ID, and computed Hjorth parameters\n",
    "participant_id = \"1\"  # Participant ID 's01' repeated 40 times\n",
    "experiment_ids = list(range(1, 41))  # Experiment IDs from 1 to 40\n",
    "\n",
    "# Create a dictionary to hold the features\n",
    "data = {\n",
    "    \"Participant_id\": participant_id,\n",
    "    \"Experiment_id\": experiment_ids,\n",
    "    \"Activity\": trial_mean_activity_final,\n",
    "    \"Mobility\": trial_mean_mobility_final,\n",
    "    \"Complexity\": trial_mean_complexity_final\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "outcome_df = pd.DataFrame(data)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(outcome_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pyentrp.entropy as ent\n",
    "\n",
    "# Initialize lists to store the features for all trials of the first participant\n",
    "all_mean_values = []\n",
    "all_std_values = []\n",
    "all_max_values = []\n",
    "all_min_values = []\n",
    "all_rms_values = []\n",
    "all_skewness_values = []\n",
    "all_kurtosis_values = []\n",
    "all_entropy_values = []\n",
    "\n",
    "# Iterate over each trial's list of subtrials\n",
    "for trial_subtrials in first_participant_subtrials:\n",
    "    # Initialize lists to store the features for subtrials of the current trial\n",
    "    mean_values = []\n",
    "    std_values = []\n",
    "    max_values = []\n",
    "    min_values = []\n",
    "    rms_values = []\n",
    "    skewness_values = []\n",
    "    kurtosis_values = []\n",
    "    entropy_values = []\n",
    "\n",
    "    # Iterate over each subtrial of the current trial\n",
    "    for subtrial_data in trial_subtrials:\n",
    "        # Flatten the subtrial data\n",
    "        flat_data = subtrial_data.get_data().flatten()\n",
    "\n",
    "        # Compute mean\n",
    "        mean_values.append(np.mean(flat_data))\n",
    "\n",
    "        # Compute standard deviation\n",
    "        std_values.append(np.std(flat_data))\n",
    "\n",
    "        # Compute maximum and minimum values\n",
    "        max_values.append(np.max(flat_data))\n",
    "        min_values.append(np.min(flat_data))\n",
    "\n",
    "        # Compute root mean square (RMS)\n",
    "        rms_values.append(np.sqrt(np.mean(flat_data**2)))\n",
    "\n",
    "        # Compute skewness and kurtosis\n",
    "        skewness_values.append(stats.skew(flat_data))\n",
    "        kurtosis_values.append(stats.kurtosis(flat_data))\n",
    "\n",
    "        # Compute sample entropy\n",
    "        sample_entropy = ent.sample_entropy(flat_data, 2, 0.2*np.std(flat_data))\n",
    "        entropy_values.append(sample_entropy)\n",
    "\n",
    "    # Append computed features for subtrials of the current trial to corresponding lists\n",
    "    all_mean_values.append(mean_values)\n",
    "    all_std_values.append(std_values)\n",
    "    all_max_values.append(max_values)\n",
    "    all_min_values.append(min_values)\n",
    "    all_rms_values.append(rms_values)\n",
    "    all_skewness_values.append(skewness_values)\n",
    "    all_kurtosis_values.append(kurtosis_values)\n",
    "    all_entropy_values.append(entropy_values)\n",
    "\n",
    "# Now all_mean_values, all_std_values, all_max_values, all_min_values, all_rms_values, all_skewness_values,\n",
    "# all_kurtosis_values, and all_entropy_values contain the computed features for each subtrial of all trials of the first participant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print computed features for each subtrial of each trial\n",
    "for i, (mean_trial, std_trial, max_trial, min_trial, rms_trial, skewness_trial, kurtosis_trial, entropy_trial) in enumerate(zip(all_mean_values, all_std_values, all_max_values, all_min_values, all_rms_values, all_skewness_values, all_kurtosis_values, all_entropy_values), start=1):\n",
    "    print(f\"Trial {i}:\")\n",
    "    for j, (mean_subtrial, std_subtrial, max_subtrial, min_subtrial, rms_subtrial, skewness_subtrial, kurtosis_subtrial, entropy_subtrial) in enumerate(zip(mean_trial, std_trial, max_trial, min_trial, rms_trial, skewness_trial, kurtosis_trial, entropy_trial), start=1):\n",
    "        print(f\"Subtrial {j}:\")\n",
    "        print(f\"Mean: {mean_subtrial}\")\n",
    "        print(f\"Standard Deviation: {std_subtrial}\")\n",
    "        print(f\"Maximum: {max_subtrial}\")\n",
    "        print(f\"Minimum: {min_subtrial}\")\n",
    "        print(f\"Root Mean Square: {rms_subtrial}\")\n",
    "        print(f\"Skewness: {skewness_subtrial}\")\n",
    "        print(f\"Kurtosis: {kurtosis_subtrial}\")\n",
    "        print(f\"Entropy: {entropy_subtrial}\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store the mean values of features for each trial\n",
    "trial_mean_values = []\n",
    "trial_std_values = []\n",
    "trial_max_values = []\n",
    "trial_min_values = []\n",
    "trial_rms_values = []\n",
    "trial_skewness_values = []\n",
    "trial_kurtosis_values = []\n",
    "trial_entropy_values = []\n",
    "\n",
    "# Iterate over each trial's features\n",
    "for trial_features in zip(all_mean_values, all_std_values, all_max_values, all_min_values, all_rms_values, all_skewness_values, all_kurtosis_values, all_entropy_values):\n",
    "    # Compute the mean value of each feature across all subtrials for the current trial\n",
    "    trial_mean_values.append(np.mean(trial_features[0]))\n",
    "    trial_std_values.append(np.mean(trial_features[1]))\n",
    "    trial_max_values.append(np.mean(trial_features[2]))\n",
    "    trial_min_values.append(np.mean(trial_features[3]))\n",
    "    trial_rms_values.append(np.mean(trial_features[4]))\n",
    "    trial_skewness_values.append(np.mean(trial_features[5]))\n",
    "    trial_kurtosis_values.append(np.mean(trial_features[6]))\n",
    "    trial_entropy_values.append(np.mean(trial_features[7]))\n",
    "\n",
    "# Print the mean values of features for each trial\n",
    "for i, (mean_val, std_val, max_val, min_val, rms_val, skewness_val, kurtosis_val, entropy_val) in enumerate(zip(trial_mean_values, trial_std_values, trial_max_values, trial_min_values, trial_rms_values, trial_skewness_values, trial_kurtosis_values, trial_entropy_values), start=1):\n",
    "    print(f\"Trial {i}:\")\n",
    "    print(f\"Mean: {mean_val}\")\n",
    "    print(f\"Standard Deviation: {std_val}\")\n",
    "    print(f\"Maximum: {max_val}\")\n",
    "    print(f\"Minimum: {min_val}\")\n",
    "    print(f\"Root Mean Square: {rms_val}\")\n",
    "    print(f\"Skewness: {skewness_val}\")\n",
    "    print(f\"Kurtosis: {kurtosis_val}\")\n",
    "    print(f\"Entropy: {entropy_val}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Create a list to hold the participant ID (s01) and experiment ID (1 to 40) for each trial\n",
    "# participant_ids = [\"s01\"] * 40\n",
    "# experiment_ids = list(range(1, 41))\n",
    "\n",
    "new_data = {\n",
    "    \"Mean\": trial_mean_values,\n",
    "    \"Standard_Deviation\": trial_std_values,\n",
    "    \"Maximum\": trial_max_values,\n",
    "    \"Minimum\": trial_min_values,\n",
    "    \"Root_Mean_Square\": trial_rms_values,\n",
    "    \"Skewness\": trial_skewness_values,\n",
    "    \"Kurtosis\": trial_kurtosis_values,\n",
    "    \"Entropy\": trial_entropy_values\n",
    "}\n",
    "\n",
    "\n",
    "# Update the existing dictionary with new features\n",
    "data.update(new_data)\n",
    "\n",
    "# Create a DataFrame from the updated dictionary\n",
    "outcome_df = pd.DataFrame(data)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(outcome_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "csv_data = pd.read_csv(\"participant_ratings.csv\")\n",
    "\n",
    "# Convert Participant_id column in CSV data to string type\n",
    "csv_data['Participant_id'] = csv_data['Participant_id'].astype(str)\n",
    "\n",
    "# Merge the CSV data with our DataFrame based on participant_id and experiment_id\n",
    "merged_data = pd.merge(outcome_df, csv_data[['Participant_id', 'Experiment_id', 'Valence', 'Arousal']], \n",
    "                       how='left', on=['Participant_id', 'Experiment_id'])\n",
    "\n",
    "# Print the merged DataFrame\n",
    "print(merged_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.fft import fft\n",
    "from scipy.stats import entropy\n",
    "\n",
    "\n",
    "fs = 128  # Sampling rate of the EEG signal\n",
    "\n",
    "def compute_energy(signal, sampling_rate, frequency_band=None):\n",
    "    \"\"\"\n",
    "    Compute the energy of the signal within a specified frequency band, or the entire signal if no band is specified.\n",
    "\n",
    "    Args:\n",
    "    - signal (numpy.ndarray): The EEG signal.\n",
    "    - sampling_rate (int): The sampling rate of the EEG signal.\n",
    "    - frequency_band (tuple, optional): The frequency range of the band (e.g., (4, 8) for Theta band). If None, computes energy for the entire signal.\n",
    "\n",
    "    Returns:\n",
    "    - energy (float): The energy of the signal within the specified frequency band, or the entire signal if no band is specified.\n",
    "    \"\"\"\n",
    "    fft_result = fft(signal)\n",
    "    freqs = np.fft.fftfreq(len(signal), d=1/sampling_rate)\n",
    "    if frequency_band is not None:\n",
    "        band_indices = np.where((freqs >= frequency_band[0]) & (freqs <= frequency_band[1]))[0]\n",
    "        band_fft = fft_result[band_indices]\n",
    "    else:\n",
    "        band_fft = fft_result\n",
    "    energy = np.sum(np.abs(band_fft)**2) / len(signal)\n",
    "    return energy\n",
    "\n",
    "\n",
    "def compute_differential_entropy(signal, sampling_rate, frequency_band):\n",
    "    \"\"\"\n",
    "    Compute the differential entropy of the signal within a frequency band.\n",
    "\n",
    "    Args:\n",
    "    - signal (numpy.ndarray): The EEG signal.\n",
    "    - sampling_rate (int): The sampling rate of the EEG signal.\n",
    "    - frequency_band (tuple): The frequency range of the band (e.g., (4, 8) for Theta band).\n",
    "\n",
    "    Returns:\n",
    "    - diff_entropy (float): The differential entropy of the signal within the frequency band.\n",
    "    \"\"\"\n",
    "    fft_result = fft(signal)\n",
    "    freqs = np.fft.fftfreq(len(signal), d=1/sampling_rate)\n",
    "    band_indices = np.where((freqs >= frequency_band[0]) & (freqs <= frequency_band[1]))[0]\n",
    "    band_fft = fft_result[band_indices]\n",
    "    band_psd = np.abs(band_fft)**2 / len(signal)\n",
    "    band_pdf = band_psd / np.sum(band_psd)\n",
    "    diff_entropy = entropy(band_pdf)\n",
    "    return diff_entropy\n",
    "\n",
    "# Define frequency bands\n",
    "theta_band = (4, 8)\n",
    "alpha_band = (8, 14)\n",
    "beta_band = (14, 31)\n",
    "gamma_band = (31, 45)\n",
    "\n",
    "# Initialize lists to store energy values for each frequency band\n",
    "theta_energy_values = []\n",
    "alpha_energy_values = []\n",
    "beta_energy_values = []\n",
    "gamma_energy_values = []\n",
    "\n",
    "# Initialize lists to store differential entropy values for each frequency band\n",
    "theta_diff_entropy_values = []\n",
    "alpha_diff_entropy_values = []\n",
    "beta_diff_entropy_values = []\n",
    "gamma_diff_entropy_values = []\n",
    "t=0\n",
    "# Loop through each trial\n",
    "for trial_subtrials in first_participant_subtrials:\n",
    "    print(t)\n",
    "    t += 1\n",
    "    # Initialize lists to store energy and differential entropy for each channel\n",
    "    trial_theta_energy_values = []\n",
    "    trial_alpha_energy_values = []\n",
    "    trial_beta_energy_values = []\n",
    "    trial_gamma_energy_values = []\n",
    "\n",
    "    trial_theta_diff_entropy_values = []\n",
    "    trial_alpha_diff_entropy_values = []\n",
    "    trial_beta_diff_entropy_values = []\n",
    "    trial_gamma_diff_entropy_values = []\n",
    "\n",
    "    # Loop through each subtrial in the trial\n",
    "    for subtrial_data in trial_subtrials:\n",
    "        # Initialize lists to store energy and differential entropy for each channel\n",
    "        channel_theta_energy_values = []\n",
    "        channel_alpha_energy_values = []\n",
    "        channel_beta_energy_values = []\n",
    "        channel_gamma_energy_values = []\n",
    "\n",
    "        channel_theta_diff_entropy_values = []\n",
    "        channel_alpha_diff_entropy_values = []\n",
    "        channel_beta_diff_entropy_values = []\n",
    "        channel_gamma_diff_entropy_values = []\n",
    "\n",
    "        # Loop through each channel in the subtrial\n",
    "        for channel_data_tuple in subtrial_data:\n",
    "            # Initialize list to store flattened channel data\n",
    "            flattened_channel_data = []\n",
    "\n",
    "            # Loop through each array within the channel data tuple\n",
    "            for data_array in channel_data_tuple:\n",
    "                # If the array has more than one dimension, flatten it\n",
    "                if data_array.ndim > 1:\n",
    "                    flattened_channel_data.append(data_array.flatten())\n",
    "                elif data_array.ndim == 1:\n",
    "                    flattened_channel_data.append(data_array)  # Add 1-dimensional arrays as is\n",
    "                else:\n",
    "                    # Skip zero-dimensional arrays\n",
    "                    continue\n",
    "\n",
    "            # Concatenate flattened channel data into a single array if there's any data\n",
    "            if flattened_channel_data:\n",
    "                channel_data = np.concatenate(flattened_channel_data)\n",
    "            else:\n",
    "                # If no data was found, skip computation for this channel\n",
    "                continue\n",
    "\n",
    "            # Compute energy in different frequency bands for the channel\n",
    "            theta_energy = compute_energy(channel_data, fs)\n",
    "            alpha_energy = compute_energy(channel_data, fs)\n",
    "            beta_energy = compute_energy(channel_data, fs)\n",
    "            gamma_energy = compute_energy(channel_data, fs)\n",
    "\n",
    "            # Compute differential entropy in different frequency bands for the channel\n",
    "            theta_diff_entropy = compute_differential_entropy(channel_data, fs, theta_band)\n",
    "            alpha_diff_entropy = compute_differential_entropy(channel_data, fs, alpha_band)\n",
    "            beta_diff_entropy = compute_differential_entropy(channel_data, fs, beta_band)\n",
    "            gamma_diff_entropy = compute_differential_entropy(channel_data, fs, gamma_band)\n",
    "\n",
    "            # Append results to channel lists\n",
    "            channel_theta_energy_values.append(theta_energy)\n",
    "            channel_alpha_energy_values.append(alpha_energy)\n",
    "            channel_beta_energy_values.append(beta_energy)\n",
    "            channel_gamma_energy_values.append(gamma_energy)\n",
    "\n",
    "            channel_theta_diff_entropy_values.append(theta_diff_entropy)\n",
    "            channel_alpha_diff_entropy_values.append(alpha_diff_entropy)\n",
    "            channel_beta_diff_entropy_values.append(beta_diff_entropy)\n",
    "            channel_gamma_diff_entropy_values.append(gamma_diff_entropy)\n",
    "\n",
    "        # Append channel-wise results to trial lists\n",
    "        trial_theta_energy_values.append(channel_theta_energy_values)\n",
    "        trial_alpha_energy_values.append(channel_alpha_energy_values)\n",
    "        trial_beta_energy_values.append(channel_beta_energy_values)\n",
    "        trial_gamma_energy_values.append(channel_gamma_energy_values)\n",
    "\n",
    "        trial_theta_diff_entropy_values.append(channel_theta_diff_entropy_values)\n",
    "        trial_alpha_diff_entropy_values.append(channel_alpha_diff_entropy_values)\n",
    "        trial_beta_diff_entropy_values.append(channel_beta_diff_entropy_values)\n",
    "        trial_gamma_diff_entropy_values.append(channel_gamma_diff_entropy_values)\n",
    "\n",
    "    # Append trial-wise results to overall lists\n",
    "    theta_energy_values.append(trial_theta_energy_values)\n",
    "    alpha_energy_values.append(trial_alpha_energy_values)\n",
    "    beta_energy_values.append(trial_beta_energy_values)\n",
    "    gamma_energy_values.append(trial_gamma_energy_values)\n",
    "\n",
    "    theta_diff_entropy_values.append(trial_theta_diff_entropy_values)\n",
    "    alpha_diff_entropy_values.append(trial_alpha_diff_entropy_values)\n",
    "    beta_diff_entropy_values.append(trial_beta_diff_entropy_values)\n",
    "    gamma_diff_entropy_values.append(trial_gamma_diff_entropy_values)\n",
    "\n",
    "\n",
    "# Compute mean energy and differential entropy across trials and subtrials\n",
    "theta_energy_mean = np.mean(theta_energy_values, axis=(1, 2 ))\n",
    "alpha_energy_mean = np.mean(alpha_energy_values, axis=(1, 2))\n",
    "beta_energy_mean = np.mean(beta_energy_values, axis=(1, 2))\n",
    "gamma_energy_mean = np.mean(gamma_energy_values, axis=(1, 2))\n",
    "\n",
    "theta_diff_entropy_mean = np.mean(theta_diff_entropy_values, axis=(1, 2))\n",
    "alpha_diff_entropy_mean = np.mean(alpha_diff_entropy_values, axis=(1, 2))\n",
    "beta_diff_entropy_mean = np.mean(beta_diff_entropy_values, axis=(1, 2))\n",
    "gamma_diff_entropy_mean = np.mean(gamma_diff_entropy_values, axis=(1, 2))\n",
    "\n",
    "# Print shapes after computing mean\n",
    "print(\"\\nShapes after computing mean:\")\n",
    "print(\"theta_energy_mean shape:\", theta_energy_mean.shape)\n",
    "print(\"alpha_energy_mean shape:\", alpha_energy_mean.shape)\n",
    "print(\"beta_energy_mean shape:\", beta_energy_mean.shape)\n",
    "print(\"gamma_energy_mean shape:\", gamma_energy_mean.shape)\n",
    "print(\"theta_diff_entropy_mean shape:\", theta_diff_entropy_mean.shape)\n",
    "print(\"alpha_diff_entropy_mean shape:\", alpha_diff_entropy_mean.shape)\n",
    "print(\"beta_diff_entropy_mean shape:\", beta_diff_entropy_mean.shape)\n",
    "print(\"gamma_diff_entropy_mean shape:\", gamma_diff_entropy_mean.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the mean values for each trial\n",
    "for i in range(len(theta_energy_mean)):\n",
    "    print(f\"Trial {i+1}:\")\n",
    "    print(f\"\\tTheta Energy: {theta_energy_mean[i]}\")\n",
    "    print(f\"\\tAlpha Energy: {alpha_energy_mean[i]}\")\n",
    "    print(f\"\\tBeta Energy: {beta_energy_mean[i]}\")\n",
    "    print(f\"\\tGamma Energy: {gamma_energy_mean[i]}\")\n",
    "    print(f\"\\tTheta Diff. Entropy: {theta_diff_entropy_mean[i]}\")\n",
    "    print(f\"\\tAlpha Diff. Entropy: {alpha_diff_entropy_mean[i]}\")\n",
    "    print(f\"\\tBeta Diff. Entropy: {beta_diff_entropy_mean[i]}\")\n",
    "    print(f\"\\tGamma Diff. Entropy: {gamma_diff_entropy_mean[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to hold the mean values\n",
    "new_data = {\n",
    "    \"Mean Theta Energy\": theta_energy_mean,\n",
    "    \"Mean Alpha Energy\": alpha_energy_mean,\n",
    "    \"Mean Beta Energy\": beta_energy_mean,\n",
    "    \"Mean Gamma Energy\": gamma_energy_mean,\n",
    "    \"Mean Theta Differential Entropy\": theta_diff_entropy_mean,\n",
    "    \"Mean Alpha Differential Entropy\": alpha_diff_entropy_mean,\n",
    "    \"Mean Beta Differential Entropy\": beta_diff_entropy_mean,\n",
    "    \"Mean Gamma Differential Entropy\": gamma_diff_entropy_mean\n",
    "}\n",
    "\n",
    "# Update the existing dictionary with new features\n",
    "data.update(new_data)\n",
    "\n",
    "# Create a DataFrame from the updated dictionary\n",
    "merged_data = pd.DataFrame(data)\n",
    "\n",
    "# Print the DataFrame\n",
    "merged_data.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pywt\n",
    "\n",
    "# Define your EEG signal, subtrials, and channels\n",
    "\n",
    "fs = 128  # Sampling rate of the EEG signal\n",
    "\n",
    "def compute_features(signal):\n",
    "    \"\"\"\n",
    "    Compute features from wavelet coefficients.\n",
    "\n",
    "    Args:\n",
    "    - signal (numpy.ndarray): The EEG signal.\n",
    "\n",
    "    Returns:\n",
    "    - features (list): List of extracted features.\n",
    "    \"\"\"\n",
    "    # Perform wavelet decomposition\n",
    "    coeffs = pywt.wavedec(signal, wavelet='db4', level=5)\n",
    "\n",
    "    # Initialize list to store features\n",
    "    features = []\n",
    "\n",
    "    # Extract statistical features from wavelet coefficients\n",
    "    for coeff in coeffs:\n",
    "        features.extend([np.mean(coeff), np.var(coeff), np.std(coeff), np.max(coeff), np.min(coeff)])\n",
    "\n",
    "    return features\n",
    "\n",
    "# Initialize lists to store features for each trial\n",
    "wavelet_features_per_trial = []\n",
    "t=0\n",
    "# Loop through each trial\n",
    "for trial_subtrials in first_participant_subtrials:\n",
    "    print(t)\n",
    "    t+=1\n",
    "    # Initialize lists to store features for each subtrial within the trial\n",
    "    wavelet_features_per_subtrial = []\n",
    "\n",
    "    # Loop through each subtrial in the trial\n",
    "    for subtrial_data in trial_subtrials:\n",
    "        # Initialize lists to store features for each channel within the subtrial\n",
    "        wavelet_features_per_channel = []\n",
    "\n",
    "        # Loop through each channel in the subtrial\n",
    "        for channel_data_tuple in subtrial_data:\n",
    "            # Initialize an empty list to store flattened channel data\n",
    "            flattened_channel_data = []\n",
    "\n",
    "            # Loop through each array within the channel data tuple\n",
    "            for data_array in channel_data_tuple:\n",
    "                # If the array has more than one dimension, flatten it\n",
    "                if data_array.ndim > 1:\n",
    "                    flattened_channel_data.append(data_array.flatten())\n",
    "                else:\n",
    "                    flattened_channel_data.append(data_array)\n",
    "\n",
    "            # Concatenate the flattened channel data into a single one-dimensional array\n",
    "            channel_data = np.concatenate(flattened_channel_data)\n",
    "\n",
    "            # Compute features for the channel data\n",
    "            features = compute_features(channel_data)\n",
    "\n",
    "            # Append features to the list\n",
    "            wavelet_features_per_channel.append(features)\n",
    "\n",
    "        # Append features for all channels in the subtrial to the list\n",
    "        wavelet_features_per_subtrial.append(wavelet_features_per_channel)\n",
    "\n",
    "    # Append features for all subtrials in the trial to the list\n",
    "    wavelet_features_per_trial.append(wavelet_features_per_subtrial)\n",
    "\n",
    "# Convert list of features to NumPy array\n",
    "wavelet_features_per_trial = np.array(wavelet_features_per_trial)\n",
    "\n",
    "# Now 'wavelet_features_per_trial' contains the extracted features from the wavelet coefficients for each trial\n",
    "print(wavelet_features_per_trial)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelet_features_per_trial_mean =np.mean(wavelet_features_per_trial, axis=(1, 2 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of wavelet_features_per_trial\n",
    "print(\"Shape of wavelet_features_per_trial:\", wavelet_features_per_trial_mean.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the mean values for each trial\n",
    "for i in range(len(wavelet_features_per_trial_mean)):\n",
    "    print(f\"Trial {i+1}:\")\n",
    "    print(f\"\\tWavelet Features: {wavelet_features_per_trial_mean[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'wavelet_features_per_trial_mean' is your array of mean wavelet features\n",
    "\n",
    "# Create a dictionary to hold the mean wavelet features\n",
    "new_wavelet_data = {}\n",
    "\n",
    "# Assuming you have 30 features\n",
    "for i in range(30):\n",
    "    new_wavelet_data[f\"Mean Wavelet Feature {i+1}\"] = wavelet_features_per_trial_mean[:, i]\n",
    "\n",
    "# Update the existing dictionary with new features\n",
    "data.update(new_wavelet_data)\n",
    "\n",
    "# Create a DataFrame from the updated dictionary\n",
    "merged_data = pd.DataFrame(data)\n",
    "\n",
    "# Print the DataFrame\n",
    "merged_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pywt\n",
    "\n",
    "# Define your EEG signal, subtrials, and channels\n",
    "fs = 128  # Sampling rate of the EEG signal\n",
    "\n",
    "def compute_wavelet_entropy(signal):\n",
    "    \"\"\"\n",
    "    Compute wavelet entropy from wavelet coefficients.\n",
    "\n",
    "    Args:\n",
    "    - signal (numpy.ndarray): The EEG signal.\n",
    "\n",
    "    Returns:\n",
    "    - entropy_values (numpy.ndarray): Wavelet entropy values.\n",
    "    \"\"\"\n",
    "    # Perform wavelet decomposition with level 4 and zero-padding\n",
    "    coeffs = pywt.wavedec(signal, wavelet='db4', level=4, mode='zero')\n",
    "\n",
    "    # Initialize list to store entropy values\n",
    "    entropy_values = []\n",
    "\n",
    "    # Calculate entropy for each wavelet coefficient\n",
    "    for coeff in coeffs:\n",
    "        # Compute probability distribution\n",
    "        prob_distribution = np.abs(coeff) / np.sum(np.abs(coeff))\n",
    "        \n",
    "        # Avoid division by zero by adding a small epsilon value\n",
    "        prob_distribution[prob_distribution == 0] = 1e-10\n",
    "\n",
    "        # Compute entropy\n",
    "        entropy = -np.sum(prob_distribution * np.log2(prob_distribution))\n",
    "\n",
    "        # Append entropy to the list\n",
    "        entropy_values.append(entropy)\n",
    "\n",
    "    return np.array(entropy_values)\n",
    "\n",
    "\n",
    "# Initialize lists to store entropy values for each trial\n",
    "wavelet_entropy_values_per_trial = []\n",
    "t = 0\n",
    "# Loop through each trial\n",
    "for trial_subtrials in first_participant_subtrials:\n",
    "    print(t)\n",
    "    t += 1\n",
    "    # Initialize lists to store entropy values for each subtrial within the trial\n",
    "    wavelet_entropy_values_per_subtrial = []\n",
    "\n",
    "    # Loop through each subtrial in the trial\n",
    "    for subtrial_data in trial_subtrials:\n",
    "        # Initialize lists to store entropy values for each channel within the subtrial\n",
    "        wavelet_entropy_values_per_channel = []\n",
    "\n",
    "        # Loop through each channel in the subtrial\n",
    "        for channel_data_tuple in subtrial_data:\n",
    "            # Initialize an empty list to store flattened channel data\n",
    "            flattened_channel_data = []\n",
    "\n",
    "            # Loop through each array within the channel data tuple\n",
    "            for data_array in channel_data_tuple:\n",
    "                # If the array has more than one dimension, flatten it\n",
    "                if data_array.ndim > 1:\n",
    "                    flattened_channel_data.append(data_array.flatten())\n",
    "                else:\n",
    "                    flattened_channel_data.append(data_array)\n",
    "\n",
    "            # Concatenate the flattened channel data into a single one-dimensional array\n",
    "            channel_data = np.concatenate(flattened_channel_data)\n",
    "\n",
    "            # Compute wavelet entropy for the channel data\n",
    "            entropy_values = compute_wavelet_entropy(channel_data)\n",
    "\n",
    "            # Append entropy values to the list\n",
    "            wavelet_entropy_values_per_channel.append(entropy_values)\n",
    "\n",
    "        # Append entropy values for all channels in the subtrial to the list\n",
    "        wavelet_entropy_values_per_subtrial.append(wavelet_entropy_values_per_channel)\n",
    "\n",
    "    # Append entropy values for all subtrials in the trial to the list\n",
    "    wavelet_entropy_values_per_trial.append(wavelet_entropy_values_per_subtrial)\n",
    "\n",
    "# Convert list of entropy values to NumPy array\n",
    "wavelet_entropy_values_per_trial = np.array(wavelet_entropy_values_per_trial)\n",
    "\n",
    "# Now 'wavelet_entropy_values_per_trial' contains the computed wavelet entropy values for each trial\n",
    "print(wavelet_entropy_values_per_trial)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of wavelet_features_per_trial: (40, 59, 32, 5)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of wavelet_features_per_trial\n",
    "print(\"Shape of wavelet_features_per_trial:\", wavelet_entropy_values_per_trial.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelet_entropy_values_per_trial_mean =np.mean(wavelet_entropy_values_per_trial, axis=(1, 2 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of wavelet_features_per_trial: (40, 5)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of wavelet_features_per_trial\n",
    "print(\"Shape of wavelet_features_per_trial:\", wavelet_entropy_values_per_trial_mean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1:\n",
      "\tWavelet Features: [2.84220301 1.73518147 1.91765824 1.82201332 1.15172277]\n",
      "Trial 2:\n",
      "\tWavelet Features: [2.84220331 1.73523108 1.91776821 1.82207189 1.15172708]\n",
      "Trial 3:\n",
      "\tWavelet Features: [2.84220287 1.73519415 1.9177198  1.82203587 1.15172307]\n",
      "Trial 4:\n",
      "\tWavelet Features: [2.84220523 1.73510309 1.91735583 1.82200925 1.15204199]\n",
      "Trial 5:\n",
      "\tWavelet Features: [2.84220535 1.73511666 1.91734507 1.82200972 1.15208316]\n",
      "Trial 6:\n",
      "\tWavelet Features: [2.8422033  1.73509674 1.91739431 1.82194081 1.15176252]\n",
      "Trial 7:\n",
      "\tWavelet Features: [2.8422033  1.7351728  1.91768864 1.82201616 1.15172115]\n",
      "Trial 8:\n",
      "\tWavelet Features: [2.84220415 1.73521864 1.91772151 1.82201628 1.15171564]\n",
      "Trial 9:\n",
      "\tWavelet Features: [2.84220469 1.73524294 1.9177651  1.82203985 1.15174143]\n",
      "Trial 10:\n",
      "\tWavelet Features: [2.84220362 1.73509404 1.91743595 1.82193325 1.15175577]\n",
      "Trial 11:\n",
      "\tWavelet Features: [2.84220334 1.73516203 1.91759612 1.82199257 1.15171444]\n",
      "Trial 12:\n",
      "\tWavelet Features: [2.84220336 1.73519408 1.91770122 1.82201936 1.15172394]\n",
      "Trial 13:\n",
      "\tWavelet Features: [2.84220412 1.73508273 1.91738967 1.82194923 1.15178913]\n",
      "Trial 14:\n",
      "\tWavelet Features: [2.84220256 1.73511152 1.91749442 1.8219579  1.15172528]\n",
      "Trial 15:\n",
      "\tWavelet Features: [2.84220329 1.73509576 1.91747414 1.82196476 1.15174487]\n",
      "Trial 16:\n",
      "\tWavelet Features: [2.84220369 1.73519166 1.91773764 1.82201997 1.15173784]\n",
      "Trial 17:\n",
      "\tWavelet Features: [2.84220355 1.73509968 1.91749397 1.8219547  1.15174777]\n",
      "Trial 18:\n",
      "\tWavelet Features: [2.84220577 1.73510752 1.91735072 1.82201998 1.15203975]\n",
      "Trial 19:\n",
      "\tWavelet Features: [2.84220389 1.73523979 1.91775757 1.82204888 1.15174081]\n",
      "Trial 20:\n",
      "\tWavelet Features: [2.84220443 1.73508663 1.91738273 1.82200489 1.15196405]\n",
      "Trial 21:\n",
      "\tWavelet Features: [2.8422043  1.73522727 1.91775662 1.8220679  1.15172969]\n",
      "Trial 22:\n",
      "\tWavelet Features: [2.84220355 1.73510502 1.91747085 1.82194031 1.15176458]\n",
      "Trial 23:\n",
      "\tWavelet Features: [2.84220478 1.73524628 1.91775726 1.82205049 1.15173376]\n",
      "Trial 24:\n",
      "\tWavelet Features: [2.84220498 1.73509503 1.91736518 1.82200031 1.15199575]\n",
      "Trial 25:\n",
      "\tWavelet Features: [2.84220403 1.73520489 1.91773641 1.82203616 1.15172391]\n",
      "Trial 26:\n",
      "\tWavelet Features: [2.84220463 1.73523229 1.91774051 1.82205787 1.15172694]\n",
      "Trial 27:\n",
      "\tWavelet Features: [2.84220187 1.7351089  1.91751874 1.82196001 1.15172353]\n",
      "Trial 28:\n",
      "\tWavelet Features: [2.84220348 1.73522132 1.91771976 1.82203139 1.1517259 ]\n",
      "Trial 29:\n",
      "\tWavelet Features: [2.84220372 1.73517018 1.91763137 1.82200152 1.1517275 ]\n",
      "Trial 30:\n",
      "\tWavelet Features: [2.84220324 1.73513786 1.91761001 1.82198667 1.15171666]\n",
      "Trial 31:\n",
      "\tWavelet Features: [2.84220418 1.73506619 1.91736064 1.82195449 1.15184873]\n",
      "Trial 32:\n",
      "\tWavelet Features: [2.84220237 1.73518706 1.91769322 1.82202095 1.15172138]\n",
      "Trial 33:\n",
      "\tWavelet Features: [2.84220374 1.73509688 1.91739977 1.82193209 1.15178352]\n",
      "Trial 34:\n",
      "\tWavelet Features: [2.8422029  1.73510015 1.91750448 1.8219615  1.15172968]\n",
      "Trial 35:\n",
      "\tWavelet Features: [2.84220327 1.73510922 1.91743801 1.82193737 1.1517529 ]\n",
      "Trial 36:\n",
      "\tWavelet Features: [2.84220354 1.73510125 1.91748973 1.8219437  1.15173312]\n",
      "Trial 37:\n",
      "\tWavelet Features: [2.84220451 1.73521947 1.91775214 1.82204687 1.15172598]\n",
      "Trial 38:\n",
      "\tWavelet Features: [2.84220408 1.73519687 1.91772786 1.82200368 1.15172057]\n",
      "Trial 39:\n",
      "\tWavelet Features: [2.84220388 1.73507939 1.91738373 1.82195248 1.15180475]\n",
      "Trial 40:\n",
      "\tWavelet Features: [2.84220383 1.73507863 1.91737202 1.82196204 1.15180879]\n"
     ]
    }
   ],
   "source": [
    "# Print the mean values for each trial\n",
    "for i in range(len(wavelet_entropy_values_per_trial_mean)):\n",
    "    print(f\"Trial {i+1}:\")\n",
    "    print(f\"\\tWavelet Features: {wavelet_entropy_values_per_trial_mean[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant_id</th>\n",
       "      <th>Experiment_id</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Mobility</th>\n",
       "      <th>Complexity</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Standard_Deviation</th>\n",
       "      <th>Maximum</th>\n",
       "      <th>Minimum</th>\n",
       "      <th>Root_Mean_Square</th>\n",
       "      <th>...</th>\n",
       "      <th>Mean Wavelet Feature 26</th>\n",
       "      <th>Mean Wavelet Feature 27</th>\n",
       "      <th>Mean Wavelet Feature 28</th>\n",
       "      <th>Mean Wavelet Feature 29</th>\n",
       "      <th>Mean Wavelet Feature 30</th>\n",
       "      <th>Mean Entropy Value 1</th>\n",
       "      <th>Mean Entropy Value 2</th>\n",
       "      <th>Mean Entropy Value 3</th>\n",
       "      <th>Mean Entropy Value 4</th>\n",
       "      <th>Mean Entropy Value 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.551833e-11</td>\n",
       "      <td>0.656182</td>\n",
       "      <td>1.562014</td>\n",
       "      <td>5.341950e-24</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>3.482417e-08</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>-0.000521</td>\n",
       "      <td>2.842203</td>\n",
       "      <td>1.735181</td>\n",
       "      <td>1.917658</td>\n",
       "      <td>1.822013</td>\n",
       "      <td>1.151723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.850130e-11</td>\n",
       "      <td>0.641845</td>\n",
       "      <td>1.566043</td>\n",
       "      <td>-9.487526e-24</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>3.482418e-08</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>-0.000521</td>\n",
       "      <td>2.842203</td>\n",
       "      <td>1.735231</td>\n",
       "      <td>1.917768</td>\n",
       "      <td>1.822072</td>\n",
       "      <td>1.151727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.687303e-11</td>\n",
       "      <td>0.647403</td>\n",
       "      <td>1.563928</td>\n",
       "      <td>-4.103842e-25</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>3.482417e-08</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>-0.000521</td>\n",
       "      <td>2.842203</td>\n",
       "      <td>1.735194</td>\n",
       "      <td>1.917720</td>\n",
       "      <td>1.822036</td>\n",
       "      <td>1.151723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2.338460e-11</td>\n",
       "      <td>0.714100</td>\n",
       "      <td>1.570787</td>\n",
       "      <td>2.643152e-24</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>-0.000023</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>3.482610e-08</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>-0.000521</td>\n",
       "      <td>2.842205</td>\n",
       "      <td>1.735103</td>\n",
       "      <td>1.917356</td>\n",
       "      <td>1.822009</td>\n",
       "      <td>1.152042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2.334399e-11</td>\n",
       "      <td>0.723316</td>\n",
       "      <td>1.570053</td>\n",
       "      <td>-1.905852e-24</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>-0.000023</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>3.482626e-08</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>-0.000521</td>\n",
       "      <td>2.842205</td>\n",
       "      <td>1.735117</td>\n",
       "      <td>1.917345</td>\n",
       "      <td>1.822010</td>\n",
       "      <td>1.152083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2.021373e-11</td>\n",
       "      <td>0.689367</td>\n",
       "      <td>1.569384</td>\n",
       "      <td>-8.951940e-24</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>3.482428e-08</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>-0.000521</td>\n",
       "      <td>2.842203</td>\n",
       "      <td>1.735097</td>\n",
       "      <td>1.917394</td>\n",
       "      <td>1.821941</td>\n",
       "      <td>1.151763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2.584953e-11</td>\n",
       "      <td>0.654612</td>\n",
       "      <td>1.560544</td>\n",
       "      <td>2.017143e-24</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>3.482417e-08</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>-0.000521</td>\n",
       "      <td>2.842203</td>\n",
       "      <td>1.735173</td>\n",
       "      <td>1.917689</td>\n",
       "      <td>1.822016</td>\n",
       "      <td>1.151721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2.664648e-11</td>\n",
       "      <td>0.647738</td>\n",
       "      <td>1.564400</td>\n",
       "      <td>-2.684886e-24</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>3.482417e-08</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>-0.000521</td>\n",
       "      <td>2.842204</td>\n",
       "      <td>1.735219</td>\n",
       "      <td>1.917722</td>\n",
       "      <td>1.822016</td>\n",
       "      <td>1.151716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2.857625e-11</td>\n",
       "      <td>0.642070</td>\n",
       "      <td>1.570750</td>\n",
       "      <td>-6.663526e-24</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>3.482419e-08</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>-0.000521</td>\n",
       "      <td>2.842205</td>\n",
       "      <td>1.735243</td>\n",
       "      <td>1.917765</td>\n",
       "      <td>1.822040</td>\n",
       "      <td>1.151741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2.066144e-11</td>\n",
       "      <td>0.686095</td>\n",
       "      <td>1.570074</td>\n",
       "      <td>-5.599310e-25</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>3.482427e-08</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>-0.000521</td>\n",
       "      <td>2.842204</td>\n",
       "      <td>1.735094</td>\n",
       "      <td>1.917436</td>\n",
       "      <td>1.821933</td>\n",
       "      <td>1.151756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2.360372e-11</td>\n",
       "      <td>0.661840</td>\n",
       "      <td>1.560834</td>\n",
       "      <td>-1.100386e-23</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>3.482417e-08</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>-0.000521</td>\n",
       "      <td>2.842203</td>\n",
       "      <td>1.735162</td>\n",
       "      <td>1.917596</td>\n",
       "      <td>1.821993</td>\n",
       "      <td>1.151714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2.657927e-11</td>\n",
       "      <td>0.649694</td>\n",
       "      <td>1.561934</td>\n",
       "      <td>-8.805871e-24</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>3.482418e-08</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>-0.000521</td>\n",
       "      <td>2.842203</td>\n",
       "      <td>1.735194</td>\n",
       "      <td>1.917701</td>\n",
       "      <td>1.822019</td>\n",
       "      <td>1.151724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2.015934e-11</td>\n",
       "      <td>0.693454</td>\n",
       "      <td>1.568120</td>\n",
       "      <td>-7.755565e-24</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>3.482431e-08</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>-0.000521</td>\n",
       "      <td>2.842204</td>\n",
       "      <td>1.735083</td>\n",
       "      <td>1.917390</td>\n",
       "      <td>1.821949</td>\n",
       "      <td>1.151789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>2.147655e-11</td>\n",
       "      <td>0.676082</td>\n",
       "      <td>1.559406</td>\n",
       "      <td>-1.857162e-24</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>3.482419e-08</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>-0.000521</td>\n",
       "      <td>2.842203</td>\n",
       "      <td>1.735112</td>\n",
       "      <td>1.917494</td>\n",
       "      <td>1.821958</td>\n",
       "      <td>1.151725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>2.158888e-11</td>\n",
       "      <td>0.678612</td>\n",
       "      <td>1.572472</td>\n",
       "      <td>2.879645e-24</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>3.482426e-08</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>-0.000521</td>\n",
       "      <td>2.842203</td>\n",
       "      <td>1.735096</td>\n",
       "      <td>1.917474</td>\n",
       "      <td>1.821965</td>\n",
       "      <td>1.151745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>2.707429e-11</td>\n",
       "      <td>0.646660</td>\n",
       "      <td>1.563060</td>\n",
       "      <td>-3.811704e-24</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>3.482418e-08</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>-0.000521</td>\n",
       "      <td>2.842204</td>\n",
       "      <td>1.735192</td>\n",
       "      <td>1.917738</td>\n",
       "      <td>1.822020</td>\n",
       "      <td>1.151738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2.157545e-11</td>\n",
       "      <td>0.676463</td>\n",
       "      <td>1.570191</td>\n",
       "      <td>-3.964729e-24</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>3.482423e-08</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>-0.000521</td>\n",
       "      <td>2.842204</td>\n",
       "      <td>1.735100</td>\n",
       "      <td>1.917494</td>\n",
       "      <td>1.821955</td>\n",
       "      <td>1.151748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2.337397e-11</td>\n",
       "      <td>0.719673</td>\n",
       "      <td>1.573360</td>\n",
       "      <td>6.607881e-25</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>-0.000023</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>3.482630e-08</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>-0.000521</td>\n",
       "      <td>2.842206</td>\n",
       "      <td>1.735108</td>\n",
       "      <td>1.917351</td>\n",
       "      <td>1.822020</td>\n",
       "      <td>1.152040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>2.843918e-11</td>\n",
       "      <td>0.642922</td>\n",
       "      <td>1.560946</td>\n",
       "      <td>5.105457e-24</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>3.482418e-08</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>-0.000521</td>\n",
       "      <td>2.842204</td>\n",
       "      <td>1.735240</td>\n",
       "      <td>1.917758</td>\n",
       "      <td>1.822049</td>\n",
       "      <td>1.151741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>2.296214e-11</td>\n",
       "      <td>0.705915</td>\n",
       "      <td>1.575812</td>\n",
       "      <td>1.794561e-24</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>3.482603e-08</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>-0.000521</td>\n",
       "      <td>2.842204</td>\n",
       "      <td>1.735087</td>\n",
       "      <td>1.917383</td>\n",
       "      <td>1.822005</td>\n",
       "      <td>1.151964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>2.865951e-11</td>\n",
       "      <td>0.640929</td>\n",
       "      <td>1.567817</td>\n",
       "      <td>2.065832e-24</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>3.482419e-08</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>-0.000521</td>\n",
       "      <td>2.842204</td>\n",
       "      <td>1.735227</td>\n",
       "      <td>1.917757</td>\n",
       "      <td>1.822068</td>\n",
       "      <td>1.151730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>2.120968e-11</td>\n",
       "      <td>0.680874</td>\n",
       "      <td>1.574048</td>\n",
       "      <td>-3.491743e-24</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>3.482428e-08</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>-0.000521</td>\n",
       "      <td>2.842204</td>\n",
       "      <td>1.735105</td>\n",
       "      <td>1.917471</td>\n",
       "      <td>1.821940</td>\n",
       "      <td>1.151765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>2.872016e-11</td>\n",
       "      <td>0.641362</td>\n",
       "      <td>1.568198</td>\n",
       "      <td>1.905852e-24</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>3.482418e-08</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>-0.000521</td>\n",
       "      <td>2.842205</td>\n",
       "      <td>1.735246</td>\n",
       "      <td>1.917757</td>\n",
       "      <td>1.822050</td>\n",
       "      <td>1.151734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2.314857e-11</td>\n",
       "      <td>0.709668</td>\n",
       "      <td>1.575536</td>\n",
       "      <td>4.030807e-24</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>3.482613e-08</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>-0.000521</td>\n",
       "      <td>2.842205</td>\n",
       "      <td>1.735095</td>\n",
       "      <td>1.917365</td>\n",
       "      <td>1.822000</td>\n",
       "      <td>1.151996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>2.709617e-11</td>\n",
       "      <td>0.647042</td>\n",
       "      <td>1.563206</td>\n",
       "      <td>7.978147e-24</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>3.482417e-08</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>-0.000521</td>\n",
       "      <td>2.842204</td>\n",
       "      <td>1.735205</td>\n",
       "      <td>1.917736</td>\n",
       "      <td>1.822036</td>\n",
       "      <td>1.151724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>2.811753e-11</td>\n",
       "      <td>0.643525</td>\n",
       "      <td>1.571288</td>\n",
       "      <td>-4.208177e-24</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>3.482418e-08</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>-0.000521</td>\n",
       "      <td>2.842205</td>\n",
       "      <td>1.735232</td>\n",
       "      <td>1.917741</td>\n",
       "      <td>1.822058</td>\n",
       "      <td>1.151727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>2.172901e-11</td>\n",
       "      <td>0.671037</td>\n",
       "      <td>1.564225</td>\n",
       "      <td>-3.255251e-24</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>3.482418e-08</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>-0.000521</td>\n",
       "      <td>2.842202</td>\n",
       "      <td>1.735109</td>\n",
       "      <td>1.917519</td>\n",
       "      <td>1.821960</td>\n",
       "      <td>1.151724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>2.686868e-11</td>\n",
       "      <td>0.647913</td>\n",
       "      <td>1.562462</td>\n",
       "      <td>-3.324807e-24</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>3.482418e-08</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>-0.000521</td>\n",
       "      <td>2.842203</td>\n",
       "      <td>1.735221</td>\n",
       "      <td>1.917720</td>\n",
       "      <td>1.822031</td>\n",
       "      <td>1.151726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>2.500143e-11</td>\n",
       "      <td>0.657193</td>\n",
       "      <td>1.560338</td>\n",
       "      <td>9.459703e-25</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>3.482418e-08</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>-0.000521</td>\n",
       "      <td>2.842204</td>\n",
       "      <td>1.735170</td>\n",
       "      <td>1.917631</td>\n",
       "      <td>1.822002</td>\n",
       "      <td>1.151728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>2.428133e-11</td>\n",
       "      <td>0.659146</td>\n",
       "      <td>1.559882</td>\n",
       "      <td>1.335488e-24</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>3.482417e-08</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>-0.000521</td>\n",
       "      <td>2.842203</td>\n",
       "      <td>1.735138</td>\n",
       "      <td>1.917610</td>\n",
       "      <td>1.821987</td>\n",
       "      <td>1.151717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>1.998703e-11</td>\n",
       "      <td>0.699373</td>\n",
       "      <td>1.577567</td>\n",
       "      <td>-4.834187e-24</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>3.482445e-08</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>-0.000521</td>\n",
       "      <td>2.842204</td>\n",
       "      <td>1.735066</td>\n",
       "      <td>1.917361</td>\n",
       "      <td>1.821954</td>\n",
       "      <td>1.151849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>2.625703e-11</td>\n",
       "      <td>0.651882</td>\n",
       "      <td>1.561600</td>\n",
       "      <td>1.891941e-24</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>3.482417e-08</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>-0.000521</td>\n",
       "      <td>2.842202</td>\n",
       "      <td>1.735187</td>\n",
       "      <td>1.917693</td>\n",
       "      <td>1.822021</td>\n",
       "      <td>1.151721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>2.019294e-11</td>\n",
       "      <td>0.690383</td>\n",
       "      <td>1.570576</td>\n",
       "      <td>-8.958895e-24</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>3.482432e-08</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>-0.000521</td>\n",
       "      <td>2.842204</td>\n",
       "      <td>1.735097</td>\n",
       "      <td>1.917400</td>\n",
       "      <td>1.821932</td>\n",
       "      <td>1.151784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>2.139519e-11</td>\n",
       "      <td>0.677262</td>\n",
       "      <td>1.560240</td>\n",
       "      <td>6.816551e-25</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>3.482419e-08</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>-0.000521</td>\n",
       "      <td>2.842203</td>\n",
       "      <td>1.735100</td>\n",
       "      <td>1.917504</td>\n",
       "      <td>1.821962</td>\n",
       "      <td>1.151730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>2.106036e-11</td>\n",
       "      <td>0.683176</td>\n",
       "      <td>1.569457</td>\n",
       "      <td>1.947586e-24</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>3.482428e-08</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>-0.000521</td>\n",
       "      <td>2.842203</td>\n",
       "      <td>1.735109</td>\n",
       "      <td>1.917438</td>\n",
       "      <td>1.821937</td>\n",
       "      <td>1.151753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>2.129666e-11</td>\n",
       "      <td>0.676971</td>\n",
       "      <td>1.564543</td>\n",
       "      <td>2.184079e-24</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>3.482420e-08</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>-0.000521</td>\n",
       "      <td>2.842204</td>\n",
       "      <td>1.735101</td>\n",
       "      <td>1.917490</td>\n",
       "      <td>1.821944</td>\n",
       "      <td>1.151733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>2.801938e-11</td>\n",
       "      <td>0.644290</td>\n",
       "      <td>1.564488</td>\n",
       "      <td>-3.616945e-24</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>3.482418e-08</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>-0.000521</td>\n",
       "      <td>2.842205</td>\n",
       "      <td>1.735219</td>\n",
       "      <td>1.917752</td>\n",
       "      <td>1.822047</td>\n",
       "      <td>1.151726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>2.723601e-11</td>\n",
       "      <td>0.645334</td>\n",
       "      <td>1.566665</td>\n",
       "      <td>5.828846e-24</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>3.482417e-08</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>-0.000521</td>\n",
       "      <td>2.842204</td>\n",
       "      <td>1.735197</td>\n",
       "      <td>1.917728</td>\n",
       "      <td>1.822004</td>\n",
       "      <td>1.151721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>2.011880e-11</td>\n",
       "      <td>0.695769</td>\n",
       "      <td>1.570195</td>\n",
       "      <td>-7.978147e-24</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>3.482435e-08</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>-0.000521</td>\n",
       "      <td>2.842204</td>\n",
       "      <td>1.735079</td>\n",
       "      <td>1.917384</td>\n",
       "      <td>1.821952</td>\n",
       "      <td>1.151805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>1.990043e-11</td>\n",
       "      <td>0.697082</td>\n",
       "      <td>1.575862</td>\n",
       "      <td>-4.639428e-24</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>3.482436e-08</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>-0.000521</td>\n",
       "      <td>2.842204</td>\n",
       "      <td>1.735079</td>\n",
       "      <td>1.917372</td>\n",
       "      <td>1.821962</td>\n",
       "      <td>1.151809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Participant_id  Experiment_id      Activity  Mobility  Complexity  \\\n",
       "0               1              1  2.551833e-11  0.656182    1.562014   \n",
       "1               1              2  2.850130e-11  0.641845    1.566043   \n",
       "2               1              3  2.687303e-11  0.647403    1.563928   \n",
       "3               1              4  2.338460e-11  0.714100    1.570787   \n",
       "4               1              5  2.334399e-11  0.723316    1.570053   \n",
       "5               1              6  2.021373e-11  0.689367    1.569384   \n",
       "6               1              7  2.584953e-11  0.654612    1.560544   \n",
       "7               1              8  2.664648e-11  0.647738    1.564400   \n",
       "8               1              9  2.857625e-11  0.642070    1.570750   \n",
       "9               1             10  2.066144e-11  0.686095    1.570074   \n",
       "10              1             11  2.360372e-11  0.661840    1.560834   \n",
       "11              1             12  2.657927e-11  0.649694    1.561934   \n",
       "12              1             13  2.015934e-11  0.693454    1.568120   \n",
       "13              1             14  2.147655e-11  0.676082    1.559406   \n",
       "14              1             15  2.158888e-11  0.678612    1.572472   \n",
       "15              1             16  2.707429e-11  0.646660    1.563060   \n",
       "16              1             17  2.157545e-11  0.676463    1.570191   \n",
       "17              1             18  2.337397e-11  0.719673    1.573360   \n",
       "18              1             19  2.843918e-11  0.642922    1.560946   \n",
       "19              1             20  2.296214e-11  0.705915    1.575812   \n",
       "20              1             21  2.865951e-11  0.640929    1.567817   \n",
       "21              1             22  2.120968e-11  0.680874    1.574048   \n",
       "22              1             23  2.872016e-11  0.641362    1.568198   \n",
       "23              1             24  2.314857e-11  0.709668    1.575536   \n",
       "24              1             25  2.709617e-11  0.647042    1.563206   \n",
       "25              1             26  2.811753e-11  0.643525    1.571288   \n",
       "26              1             27  2.172901e-11  0.671037    1.564225   \n",
       "27              1             28  2.686868e-11  0.647913    1.562462   \n",
       "28              1             29  2.500143e-11  0.657193    1.560338   \n",
       "29              1             30  2.428133e-11  0.659146    1.559882   \n",
       "30              1             31  1.998703e-11  0.699373    1.577567   \n",
       "31              1             32  2.625703e-11  0.651882    1.561600   \n",
       "32              1             33  2.019294e-11  0.690383    1.570576   \n",
       "33              1             34  2.139519e-11  0.677262    1.560240   \n",
       "34              1             35  2.106036e-11  0.683176    1.569457   \n",
       "35              1             36  2.129666e-11  0.676971    1.564543   \n",
       "36              1             37  2.801938e-11  0.644290    1.564488   \n",
       "37              1             38  2.723601e-11  0.645334    1.566665   \n",
       "38              1             39  2.011880e-11  0.695769    1.570195   \n",
       "39              1             40  1.990043e-11  0.697082    1.575862   \n",
       "\n",
       "            Mean  Standard_Deviation   Maximum   Minimum  Root_Mean_Square  \\\n",
       "0   5.341950e-24            0.000005  0.000019 -0.000020          0.000005   \n",
       "1  -9.487526e-24            0.000005  0.000021 -0.000022          0.000005   \n",
       "2  -4.103842e-25            0.000005  0.000021 -0.000021          0.000005   \n",
       "3   2.643152e-24            0.000005  0.000023 -0.000023          0.000005   \n",
       "4  -1.905852e-24            0.000005  0.000023 -0.000023          0.000005   \n",
       "5  -8.951940e-24            0.000004  0.000018 -0.000019          0.000004   \n",
       "6   2.017143e-24            0.000005  0.000019 -0.000020          0.000005   \n",
       "7  -2.684886e-24            0.000005  0.000020 -0.000020          0.000005   \n",
       "8  -6.663526e-24            0.000005  0.000021 -0.000022          0.000005   \n",
       "9  -5.599310e-25            0.000004  0.000019 -0.000019          0.000004   \n",
       "10 -1.100386e-23            0.000005  0.000019 -0.000020          0.000005   \n",
       "11 -8.805871e-24            0.000005  0.000020 -0.000021          0.000005   \n",
       "12 -7.755565e-24            0.000004  0.000019 -0.000019          0.000004   \n",
       "13 -1.857162e-24            0.000004  0.000019 -0.000019          0.000004   \n",
       "14  2.879645e-24            0.000005  0.000019 -0.000020          0.000005   \n",
       "15 -3.811704e-24            0.000005  0.000020 -0.000021          0.000005   \n",
       "16 -3.964729e-24            0.000005  0.000019 -0.000020          0.000005   \n",
       "17  6.607881e-25            0.000005  0.000022 -0.000023          0.000005   \n",
       "18  5.105457e-24            0.000005  0.000021 -0.000021          0.000005   \n",
       "19  1.794561e-24            0.000005  0.000021 -0.000021          0.000005   \n",
       "20  2.065832e-24            0.000005  0.000021 -0.000022          0.000005   \n",
       "21 -3.491743e-24            0.000004  0.000019 -0.000019          0.000004   \n",
       "22  1.905852e-24            0.000005  0.000021 -0.000022          0.000005   \n",
       "23  4.030807e-24            0.000005  0.000021 -0.000022          0.000005   \n",
       "24  7.978147e-24            0.000005  0.000020 -0.000021          0.000005   \n",
       "25 -4.208177e-24            0.000005  0.000021 -0.000022          0.000005   \n",
       "26 -3.255251e-24            0.000005  0.000019 -0.000019          0.000005   \n",
       "27 -3.324807e-24            0.000005  0.000020 -0.000020          0.000005   \n",
       "28  9.459703e-25            0.000005  0.000020 -0.000021          0.000005   \n",
       "29  1.335488e-24            0.000005  0.000020 -0.000020          0.000005   \n",
       "30 -4.834187e-24            0.000004  0.000019 -0.000019          0.000004   \n",
       "31  1.891941e-24            0.000005  0.000020 -0.000020          0.000005   \n",
       "32 -8.958895e-24            0.000004  0.000018 -0.000019          0.000004   \n",
       "33  6.816551e-25            0.000004  0.000019 -0.000019          0.000004   \n",
       "34  1.947586e-24            0.000004  0.000019 -0.000019          0.000004   \n",
       "35  2.184079e-24            0.000004  0.000019 -0.000019          0.000004   \n",
       "36 -3.616945e-24            0.000005  0.000020 -0.000021          0.000005   \n",
       "37  5.828846e-24            0.000005  0.000021 -0.000021          0.000005   \n",
       "38 -7.978147e-24            0.000004  0.000019 -0.000020          0.000004   \n",
       "39 -4.639428e-24            0.000004  0.000019 -0.000020          0.000004   \n",
       "\n",
       "    ...  Mean Wavelet Feature 26  Mean Wavelet Feature 27  \\\n",
       "0   ...                  0.00001             3.482417e-08   \n",
       "1   ...                  0.00001             3.482418e-08   \n",
       "2   ...                  0.00001             3.482417e-08   \n",
       "3   ...                  0.00001             3.482610e-08   \n",
       "4   ...                  0.00001             3.482626e-08   \n",
       "5   ...                  0.00001             3.482428e-08   \n",
       "6   ...                  0.00001             3.482417e-08   \n",
       "7   ...                  0.00001             3.482417e-08   \n",
       "8   ...                  0.00001             3.482419e-08   \n",
       "9   ...                  0.00001             3.482427e-08   \n",
       "10  ...                  0.00001             3.482417e-08   \n",
       "11  ...                  0.00001             3.482418e-08   \n",
       "12  ...                  0.00001             3.482431e-08   \n",
       "13  ...                  0.00001             3.482419e-08   \n",
       "14  ...                  0.00001             3.482426e-08   \n",
       "15  ...                  0.00001             3.482418e-08   \n",
       "16  ...                  0.00001             3.482423e-08   \n",
       "17  ...                  0.00001             3.482630e-08   \n",
       "18  ...                  0.00001             3.482418e-08   \n",
       "19  ...                  0.00001             3.482603e-08   \n",
       "20  ...                  0.00001             3.482419e-08   \n",
       "21  ...                  0.00001             3.482428e-08   \n",
       "22  ...                  0.00001             3.482418e-08   \n",
       "23  ...                  0.00001             3.482613e-08   \n",
       "24  ...                  0.00001             3.482417e-08   \n",
       "25  ...                  0.00001             3.482418e-08   \n",
       "26  ...                  0.00001             3.482418e-08   \n",
       "27  ...                  0.00001             3.482418e-08   \n",
       "28  ...                  0.00001             3.482418e-08   \n",
       "29  ...                  0.00001             3.482417e-08   \n",
       "30  ...                  0.00001             3.482445e-08   \n",
       "31  ...                  0.00001             3.482417e-08   \n",
       "32  ...                  0.00001             3.482432e-08   \n",
       "33  ...                  0.00001             3.482419e-08   \n",
       "34  ...                  0.00001             3.482428e-08   \n",
       "35  ...                  0.00001             3.482420e-08   \n",
       "36  ...                  0.00001             3.482418e-08   \n",
       "37  ...                  0.00001             3.482417e-08   \n",
       "38  ...                  0.00001             3.482435e-08   \n",
       "39  ...                  0.00001             3.482436e-08   \n",
       "\n",
       "    Mean Wavelet Feature 28  Mean Wavelet Feature 29  Mean Wavelet Feature 30  \\\n",
       "0                  0.000187                 0.001985                -0.000521   \n",
       "1                  0.000187                 0.001985                -0.000521   \n",
       "2                  0.000187                 0.001985                -0.000521   \n",
       "3                  0.000187                 0.001985                -0.000521   \n",
       "4                  0.000187                 0.001985                -0.000521   \n",
       "5                  0.000187                 0.001985                -0.000521   \n",
       "6                  0.000187                 0.001985                -0.000521   \n",
       "7                  0.000187                 0.001985                -0.000521   \n",
       "8                  0.000187                 0.001985                -0.000521   \n",
       "9                  0.000187                 0.001985                -0.000521   \n",
       "10                 0.000187                 0.001985                -0.000521   \n",
       "11                 0.000187                 0.001985                -0.000521   \n",
       "12                 0.000187                 0.001985                -0.000521   \n",
       "13                 0.000187                 0.001985                -0.000521   \n",
       "14                 0.000187                 0.001985                -0.000521   \n",
       "15                 0.000187                 0.001985                -0.000521   \n",
       "16                 0.000187                 0.001985                -0.000521   \n",
       "17                 0.000187                 0.001985                -0.000521   \n",
       "18                 0.000187                 0.001985                -0.000521   \n",
       "19                 0.000187                 0.001985                -0.000521   \n",
       "20                 0.000187                 0.001985                -0.000521   \n",
       "21                 0.000187                 0.001985                -0.000521   \n",
       "22                 0.000187                 0.001985                -0.000521   \n",
       "23                 0.000187                 0.001985                -0.000521   \n",
       "24                 0.000187                 0.001985                -0.000521   \n",
       "25                 0.000187                 0.001985                -0.000521   \n",
       "26                 0.000187                 0.001985                -0.000521   \n",
       "27                 0.000187                 0.001985                -0.000521   \n",
       "28                 0.000187                 0.001985                -0.000521   \n",
       "29                 0.000187                 0.001985                -0.000521   \n",
       "30                 0.000187                 0.001985                -0.000521   \n",
       "31                 0.000187                 0.001985                -0.000521   \n",
       "32                 0.000187                 0.001985                -0.000521   \n",
       "33                 0.000187                 0.001985                -0.000521   \n",
       "34                 0.000187                 0.001985                -0.000521   \n",
       "35                 0.000187                 0.001985                -0.000521   \n",
       "36                 0.000187                 0.001985                -0.000521   \n",
       "37                 0.000187                 0.001985                -0.000521   \n",
       "38                 0.000187                 0.001985                -0.000521   \n",
       "39                 0.000187                 0.001985                -0.000521   \n",
       "\n",
       "    Mean Entropy Value 1  Mean Entropy Value 2  Mean Entropy Value 3  \\\n",
       "0               2.842203              1.735181              1.917658   \n",
       "1               2.842203              1.735231              1.917768   \n",
       "2               2.842203              1.735194              1.917720   \n",
       "3               2.842205              1.735103              1.917356   \n",
       "4               2.842205              1.735117              1.917345   \n",
       "5               2.842203              1.735097              1.917394   \n",
       "6               2.842203              1.735173              1.917689   \n",
       "7               2.842204              1.735219              1.917722   \n",
       "8               2.842205              1.735243              1.917765   \n",
       "9               2.842204              1.735094              1.917436   \n",
       "10              2.842203              1.735162              1.917596   \n",
       "11              2.842203              1.735194              1.917701   \n",
       "12              2.842204              1.735083              1.917390   \n",
       "13              2.842203              1.735112              1.917494   \n",
       "14              2.842203              1.735096              1.917474   \n",
       "15              2.842204              1.735192              1.917738   \n",
       "16              2.842204              1.735100              1.917494   \n",
       "17              2.842206              1.735108              1.917351   \n",
       "18              2.842204              1.735240              1.917758   \n",
       "19              2.842204              1.735087              1.917383   \n",
       "20              2.842204              1.735227              1.917757   \n",
       "21              2.842204              1.735105              1.917471   \n",
       "22              2.842205              1.735246              1.917757   \n",
       "23              2.842205              1.735095              1.917365   \n",
       "24              2.842204              1.735205              1.917736   \n",
       "25              2.842205              1.735232              1.917741   \n",
       "26              2.842202              1.735109              1.917519   \n",
       "27              2.842203              1.735221              1.917720   \n",
       "28              2.842204              1.735170              1.917631   \n",
       "29              2.842203              1.735138              1.917610   \n",
       "30              2.842204              1.735066              1.917361   \n",
       "31              2.842202              1.735187              1.917693   \n",
       "32              2.842204              1.735097              1.917400   \n",
       "33              2.842203              1.735100              1.917504   \n",
       "34              2.842203              1.735109              1.917438   \n",
       "35              2.842204              1.735101              1.917490   \n",
       "36              2.842205              1.735219              1.917752   \n",
       "37              2.842204              1.735197              1.917728   \n",
       "38              2.842204              1.735079              1.917384   \n",
       "39              2.842204              1.735079              1.917372   \n",
       "\n",
       "    Mean Entropy Value 4  Mean Entropy Value 5  \n",
       "0               1.822013              1.151723  \n",
       "1               1.822072              1.151727  \n",
       "2               1.822036              1.151723  \n",
       "3               1.822009              1.152042  \n",
       "4               1.822010              1.152083  \n",
       "5               1.821941              1.151763  \n",
       "6               1.822016              1.151721  \n",
       "7               1.822016              1.151716  \n",
       "8               1.822040              1.151741  \n",
       "9               1.821933              1.151756  \n",
       "10              1.821993              1.151714  \n",
       "11              1.822019              1.151724  \n",
       "12              1.821949              1.151789  \n",
       "13              1.821958              1.151725  \n",
       "14              1.821965              1.151745  \n",
       "15              1.822020              1.151738  \n",
       "16              1.821955              1.151748  \n",
       "17              1.822020              1.152040  \n",
       "18              1.822049              1.151741  \n",
       "19              1.822005              1.151964  \n",
       "20              1.822068              1.151730  \n",
       "21              1.821940              1.151765  \n",
       "22              1.822050              1.151734  \n",
       "23              1.822000              1.151996  \n",
       "24              1.822036              1.151724  \n",
       "25              1.822058              1.151727  \n",
       "26              1.821960              1.151724  \n",
       "27              1.822031              1.151726  \n",
       "28              1.822002              1.151728  \n",
       "29              1.821987              1.151717  \n",
       "30              1.821954              1.151849  \n",
       "31              1.822021              1.151721  \n",
       "32              1.821932              1.151784  \n",
       "33              1.821962              1.151730  \n",
       "34              1.821937              1.151753  \n",
       "35              1.821944              1.151733  \n",
       "36              1.822047              1.151726  \n",
       "37              1.822004              1.151721  \n",
       "38              1.821952              1.151805  \n",
       "39              1.821962              1.151809  \n",
       "\n",
       "[40 rows x 56 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'wavelet_features_per_trial_mean' is your array of mean wavelet features\n",
    "\n",
    "# Create a dictionary to hold the mean wavelet features\n",
    "new_wavelet_data = {}\n",
    "\n",
    "# Assuming you have 30 features\n",
    "for i in range(5):\n",
    "    new_wavelet_data[f\"Mean Entropy Value {i+1}\"] = wavelet_entropy_values_per_trial_mean[:, i]\n",
    "\n",
    "# Update the existing dictionary with new features\n",
    "data.update(new_wavelet_data)\n",
    "\n",
    "# Create a DataFrame from the updated dictionary\n",
    "merged_data = pd.DataFrame(data)\n",
    "\n",
    "# Print the DataFrame\n",
    "merged_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_auto_correlation(signal):\n",
    "    \"\"\"\n",
    "    Compute auto-correlation features from the signal.\n",
    "\n",
    "    Args:\n",
    "    - signal (numpy.ndarray): The signal.\n",
    "\n",
    "    Returns:\n",
    "    - features (list): List of auto-correlation features.\n",
    "    \"\"\"\n",
    "    # Compute auto-correlation\n",
    "    auto_corr = np.correlate(signal, signal, mode='full')\n",
    "\n",
    "    # Extract relevant features from auto-correlation\n",
    "    features = [\n",
    "        np.mean(auto_corr),\n",
    "        np.max(auto_corr),\n",
    "        np.min(auto_corr),\n",
    "        np.std(auto_corr)\n",
    "    ]\n",
    "\n",
    "    return features\n",
    "\n",
    "def compute_zero_crossing_rate(signal):\n",
    "    \"\"\"\n",
    "    Compute zero crossing rate features from the signal.\n",
    "\n",
    "    Args:\n",
    "    - signal (numpy.ndarray): The signal.\n",
    "\n",
    "    Returns:\n",
    "    - features (list): List of zero crossing rate features.\n",
    "    \"\"\"\n",
    "    # Count zero crossings\n",
    "    zero_crossings = np.where(np.diff(np.sign(signal)))[0]\n",
    "\n",
    "    # Compute zero crossing rate\n",
    "    zero_crossing_rate = len(zero_crossings) / len(signal)\n",
    "\n",
    "    return [zero_crossing_rate]\n",
    "\n",
    "# Initialize lists to store features\n",
    "auto_corr_features = []\n",
    "zero_crossing_rate_features = []\n",
    "\n",
    "# Loop through each subtrial\n",
    "for subtrial_data in first_trial_subtrials:\n",
    "    # Loop through each channel in the subtrial\n",
    "    for channel_data_tuple in subtrial_data:\n",
    "        # Initialize list to store flattened channel data\n",
    "        flattened_channel_data = []\n",
    "\n",
    "        # Loop through each array within the channel data tuple\n",
    "        for data_array in channel_data_tuple:\n",
    "            # If the array has more than one dimension, flatten it\n",
    "            if data_array.ndim > 1:\n",
    "                flattened_channel_data.append(data_array.flatten())\n",
    "            else:\n",
    "                flattened_channel_data.append(data_array)\n",
    "\n",
    "        # Concatenate flattened channel data into a single array\n",
    "        channel_data = np.concatenate(flattened_channel_data)\n",
    "\n",
    "        # Compute auto-correlation features for the channel data\n",
    "        auto_corr_features.extend(compute_auto_correlation(channel_data))\n",
    "\n",
    "        # Compute zero crossing rate features for the channel data\n",
    "        zero_crossing_rate_features.extend(compute_zero_crossing_rate(channel_data))\n",
    "\n",
    "# Convert lists of features to NumPy arrays\n",
    "auto_corr_features = np.array(auto_corr_features)\n",
    "zero_crossing_rate_features = np.array(zero_crossing_rate_features)\n",
    "\n",
    "print(auto_corr_features)\n",
    "print(zero_crossing_rate_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(auto_corr_features))\n",
    "print(len(zero_crossing_rate_features))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
